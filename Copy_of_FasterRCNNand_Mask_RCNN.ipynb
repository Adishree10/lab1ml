{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPwfgye31zvu",
        "outputId": "04a1bf1c-cc6e-4759-d102-70a03a719ef2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting thop\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from thop) (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->thop) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->thop)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->thop)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->thop)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->thop)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->thop)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->thop)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->thop)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->thop)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->thop)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->thop)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->thop) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->thop) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->thop) (3.0.2)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 thop-0.1.1.post2209072238\n"
          ]
        }
      ],
      "source": [
        "!pip install thop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "ClgF_XEhS_Eo",
        "outputId": "cbe1dbfa-d80a-426d-d186-f3ae4c92b1f5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-5-94edaa06a0eb>, line 16)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-94edaa06a0eb>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    def load_image(/content/2 (1).jpg):\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import psutil\n",
        "import time\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import thop\n",
        "from PIL import Image, ImageDraw\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "from pycocotools import coco\n",
        "\n",
        "#  Load an image and transform it into a tensor\n",
        "def load_image(/content/2 (1).jpg):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    return transform(image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "def measure_performance(model, image_tensor):\n",
        "    process = psutil.Process(os.getpid())\n",
        "    memory_before = process.memory_info().rss  # Memory before inference in bytes\n",
        "\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        prediction = model(image_tensor)\n",
        "    inference_time = time.time() - start_time\n",
        "\n",
        "    memory_after = process.memory_info().rss  # Memory after inference in bytes\n",
        "    memory_used = (memory_after - memory_before) / (1024 * 1024)  # Convert to MB\n",
        "\n",
        "    return prediction, inference_time, memory_used\n",
        "\n",
        "# Function to calculate FLOPS\n",
        "def calculate_flops(model, image_tensor):\n",
        "    macs, params = thop.profile(model, inputs=(image_tensor,))\n",
        "    return macs, params\n",
        "\n",
        "\n",
        "def visualize_detections(image, model, threshold=0.5, save_path=None):\n",
        "    # Run the model to get predictions\n",
        "    with torch.no_grad():\n",
        "        prediction = model(image)\n",
        "\n",
        "    # Extract boxes, labels, and scores\n",
        "    boxes = prediction[0]['boxes']\n",
        "    labels = prediction[0]['labels']\n",
        "    scores = prediction[0]['scores']\n",
        "\n",
        "    # Filter out boxes with scores less than the threshold\n",
        "    keep = scores >= threshold\n",
        "    boxes = boxes[keep]\n",
        "    labels = labels[keep]\n",
        "    scores = scores[keep]\n",
        "\n",
        "    # Convert the image back to PIL for visualization\n",
        "    image = image.squeeze(0).permute(1, 2, 0).numpy()\n",
        "    image = (image * 255).astype(np.uint8)\n",
        "    image_pil = Image.fromarray(image)\n",
        "\n",
        "    draw = ImageDraw.Draw(image_pil)\n",
        "\n",
        "    # Draw boxes and labels on the image\n",
        "    for box, label, score in zip(boxes, labels, scores):\n",
        "        xmin, ymin, xmax, ymax = box.tolist()\n",
        "        draw.rectangle([xmin, ymin, xmax, ymax], outline=\"red\", width=3)\n",
        "        draw.text((xmin, ymin), f\"{label.item()}:{score:.2f}\", fill=\"yellow\")\n",
        "\n",
        "    # Save the image with detections if save_path is provided\n",
        "    if save_path:\n",
        "        image_pil.save(save_path)\n",
        "\n",
        "    return image_pil\n",
        "\n",
        "\n",
        "def compare_models(image_path):\n",
        "    # Load image\n",
        "    image_tensor = load_image(image_path)\n",
        "\n",
        "    # Load pre-trained Faster R-CNN and Mask R-CNN models from torchvision\n",
        "    faster_rcnn_model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    mask_rcnn_model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "    # Set models to evaluation mode\n",
        "    faster_rcnn_model.eval()\n",
        "    mask_rcnn_model.eval()\n",
        "\n",
        "    # Measure performance for Faster R-CNN\n",
        "    print(\"Measuring Faster R-CNN performance...\")\n",
        "    faster_rcnn_prediction, faster_rcnn_inference_time, faster_rcnn_memory = measure_performance(faster_rcnn_model, image_tensor)\n",
        "    faster_rcnn_macs, faster_rcnn_params = calculate_flops(faster_rcnn_model, image_tensor)\n",
        "    print(f\"Faster R-CNN Inference Time: {faster_rcnn_inference_time:.4f} seconds\")\n",
        "    print(f\"Faster R-CNN Memory Usage: {faster_rcnn_memory:.2f} MB\")\n",
        "    print(f\"Faster R-CNN FLOPS: {faster_rcnn_macs / 1e9:.2f} GFLOPS\")  # Convert to GFLOPS\n",
        "    print(f\"Faster R-CNN Parameters: {faster_rcnn_params / 1e6:.2f} M\")\n",
        "\n",
        "    # Visualize and save detection results for Faster R-CNN\n",
        "    faster_rcnn_image_with_detections = visualize_detections(image_tensor, faster_rcnn_model, save_path=\"faster_rcnn_detections.jpg\")\n",
        "\n",
        "    # Measure performance for Mask R-CNN\n",
        "    print(\"Measuring Mask R-CNN performance...\")\n",
        "    mask_rcnn_prediction, mask_rcnn_inference_time, mask_rcnn_memory = measure_performance(mask_rcnn_model, image_tensor)\n",
        "    mask_rcnn_macs, mask_rcnn_params = calculate_flops(mask_rcnn_model, image_tensor)\n",
        "    print(f\"Mask R-CNN Inference Time: {mask_rcnn_inference_time:.4f} seconds\")\n",
        "    print(f\"Mask R-CNN Memory Usage: {mask_rcnn_memory:.2f} MB\")\n",
        "    print(f\"Mask R-CNN FLOPS: {mask_rcnn_macs / 1e9:.2f} GFLOPS\")  # Convert to GFLOPS\n",
        "    print(f\"Mask R-CNN Parameters: {mask_rcnn_params / 1e6:.2f} M\")\n",
        "\n",
        "    # Visualize and save detection results for Mask R-CNN\n",
        "    mask_rcnn_image_with_detections = visualize_detections(image_tensor, mask_rcnn_model, save_path=\"mask_rcnn_detections.jpg\")\n",
        "\n",
        "    # Plot comparison graphs and save to files\n",
        "    models = ['Faster R-CNN', 'Mask R-CNN']\n",
        "    inference_times = [faster_rcnn_inference_time, mask_rcnn_inference_time]\n",
        "    memory_usage = [faster_rcnn_memory, mask_rcnn_memory]\n",
        "    flops = [faster_rcnn_macs / 1e9, mask_rcnn_macs / 1e9]  # Convert to GFLOPS\n",
        "    parameters = [faster_rcnn_params / 1e6, mask_rcnn_params / 1e6]  # Convert to M (millions)\n",
        "\n",
        "    # Create subplots for comparison\n",
        "    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "    # Inference Time Plot\n",
        "    axs[0, 0].bar(models, inference_times, color=['blue', 'orange'])\n",
        "    axs[0, 0].set_title('Inference Time (seconds)')\n",
        "    axs[0, 0].set_ylabel('Time (seconds)')\n",
        "\n",
        "    # Memory Usage Plot\n",
        "    axs[0, 1].bar(models, memory_usage, color=['blue', 'orange'])\n",
        "    axs[0, 1].set_title('Memory Usage (MB)')\n",
        "    axs[0, 1].set_ylabel('Memory (MB)')\n",
        "\n",
        "    # FLOPS Plot\n",
        "    axs[1, 0].bar(models, flops, color=['blue', 'orange'])\n",
        "    axs[1, 0].set_title('FLOPS (GFLOPS)')\n",
        "    axs[1, 0].set_ylabel('FLOPS (GFLOPS)')\n",
        "\n",
        "    # Parameters Plot\n",
        "    axs[1, 1].bar(models, parameters, color=['blue', 'orange'])\n",
        "    axs[1, 1].set_title('Parameters (Millions)')\n",
        "    axs[1, 1].set_ylabel('Parameters (M)')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"model_comparison_plots.png\")  # Save the comparison plot\n",
        "\n",
        "    # Display detection results for both models and save the images\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "    # Faster R-CNN Detections\n",
        "    ax[0].imshow(faster_rcnn_image_with_detections)\n",
        "    ax[0].set_title('Faster R-CNN Detections')\n",
        "    ax[0].axis('off')\n",
        "\n",
        "    # Mask R-CNN Detections\n",
        "    ax[1].imshow(mask_rcnn_image_with_detections)\n",
        "    ax[1].set_title('Mask R-CNN Detections')\n",
        "    ax[1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"detections_comparison.png\")  # Save the detection images\n",
        "\n",
        "# Run the comparison on a sample image\n",
        "image_path = \"/content/2.jpg\"  # Replace with your image path\n",
        "compare_models(image_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ewcwy-6oC9HN"
      },
      "outputs": [],
      "source": [
        "### Write a code of any one TWO stage object detection  model performnce evaluations\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import psutil\n",
        "import time\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import thop\n",
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "\n",
        "def load_image(/content/2 (1).jpg):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    return transform(image).unsqueeze(0)\n",
        "\n",
        "def measure_performance(model, image_tensor):\n",
        "    process = psutil.Process(os.getpid())\n",
        "    memory_before = process.memory_info().rss\n",
        "\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        prediction = model(image_tensor)\n",
        "    inference_time = time.time() - start_time\n",
        "\n",
        "    memory_after = process.memory_info().rss\n",
        "    memory_used = (memory_after - memory_before) / (1024 * 1024)\n",
        "\n",
        "    return prediction, inference_time, memory_used\n",
        "\n",
        "def calculate_flops(model, image_tensor):\n",
        "    macs, params = thop.profile(model, inputs=(image_tensor,))\n",
        "    return macs, params\n",
        "\n",
        "def visualize_detections(image_tensor, model, threshold=0.5, save_path=None):\n",
        "    with torch.no_grad():\n",
        "        prediction = model(image_tensor)\n",
        "\n",
        "    boxes = prediction[0]['boxes']\n",
        "    labels = prediction[0]['labels']\n",
        "    scores = prediction[0]['scores']\n",
        "\n",
        "    keep = scores >= threshold\n",
        "    boxes = boxes[keep]\n",
        "    labels = labels[keep]\n",
        "    scores = scores[keep]\n",
        "\n",
        "    image = image_tensor.squeeze(0).permute(1, 2, 0).numpy()\n",
        "    image = (image * 255).astype(np.uint8)\n",
        "    image_pil = Image.fromarray(image)\n",
        "\n",
        "    draw = ImageDraw.Draw(image_pil)\n",
        "    for box, label, score in zip(boxes, labels, scores):\n",
        "        xmin, ymin, xmax, ymax = box.tolist()\n",
        "        draw.rectangle([xmin, ymin, xmax, ymax], outline=\"red\", width=3)\n",
        "        draw.text((xmin, ymin), f\"{label.item()}:{score:.2f}\", fill=\"yellow\")\n",
        "\n",
        "    if save_path:\n",
        "        image_pil.save(save_path)\n",
        "\n",
        "    return image_pil\n",
        "\n",
        "def evaluate_faster_rcnn(image_path):\n",
        "    image_tensor = load_image(image_path)\n",
        "\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    model.eval()\n",
        "\n",
        "    print(\"Evaluating Faster R-CNN performance...\")\n",
        "    prediction, inference_time, memory_used = measure_performance(model, image_tensor)\n",
        "    macs, params = calculate_flops(model, image_tensor)\n",
        "\n",
        "    print(f\"Inference Time: {inference_time:.4f} seconds\")\n",
        "    print(f\"Memory Usage: {memory_used:.2f} MB\")\n",
        "    print(f\"FLOPS: {macs / 1e9:.2f} GFLOPS\")\n",
        "    print(f\"Parameters: {params / 1e6:.2f} M\")\n",
        "\n",
        "    detection_image = visualize_detections(image_tensor, model, save_path=\"faster_rcnn_detections.jpg\")\n",
        "\n",
        "    plt.imshow(detection_image)\n",
        "    plt.title(\"Faster R-CNN Detections\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "image_path = \"/content/2.jpg\"\n",
        "evaluate_faster_rcnn(image_path)\n"
      ],
      "metadata": {
        "id": "Xzv_KfNwssI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5GHgxVYC9HQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}