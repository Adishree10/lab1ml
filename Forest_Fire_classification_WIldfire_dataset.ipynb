{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA0Qbez1HeJ6",
        "outputId": "024506a7-57e5-4750-d02e-2c225257d6bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wildfire_dataset_path = '/content/drive/MyDrive/Forest Fire Project/Datasets/Wildfire Detection Image Data'"
      ],
      "metadata": {
        "id": "YSBkpL5QIZo7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZzaYDueIoVN",
        "outputId": "dd90a259-6c1e-4511-9512-c4e7207315e8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.4)\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "import time\n",
        "import onnx"
      ],
      "metadata": {
        "id": "BxZZqtw8Ije_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define the transformations for training and validation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize images to 224x224 for the model\n",
        "    transforms.ToTensor(),  # Convert images to tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
        "])\n",
        "\n",
        "# Load the dataset\n",
        "train_data = datasets.ImageFolder(root=f'{wildfire_dataset_path}/train', transform=transform)\n",
        "val_data = datasets.ImageFolder(root=f'{wildfire_dataset_path}/val', transform=transform)\n",
        "test_data = datasets.ImageFolder(root=f'{wildfire_dataset_path}/test', transform=transform)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "EXSTac8YLCVg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(128 * 28 * 28, 512)\n",
        "        self.fc2 = nn.Linear(512, 2)  # 2 classes: fire, nofire\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = self.pool(self.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 128 * 28 * 28)  # Flatten the tensor\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "5hNneR_PLG-L"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the device to GPU if available, otherwise use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Model initialization\n",
        "model = CustomCNN().to(device)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Function for training\n",
        "def train_model(model, train_loader, val_loader, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_acc = evaluate_model(model, val_loader)\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {running_loss/len(train_loader):.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "\n",
        "# Function to evaluate model on validation set\n",
        "def evaluate_model(model, val_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_loader, val_loader, epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0f3I8X6LlBm",
        "outputId": "546c9b77-d159-4010-ccb3-7c12b034273e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Train Loss: 0.7008, Val Acc: 95.00%\n",
            "Epoch [2/10], Train Loss: 0.1614, Val Acc: 96.25%\n",
            "Epoch [3/10], Train Loss: 0.1038, Val Acc: 97.50%\n",
            "Epoch [4/10], Train Loss: 0.0805, Val Acc: 97.50%\n",
            "Epoch [5/10], Train Loss: 0.0650, Val Acc: 97.50%\n",
            "Epoch [6/10], Train Loss: 0.0721, Val Acc: 95.00%\n",
            "Epoch [7/10], Train Loss: 0.0647, Val Acc: 96.25%\n",
            "Epoch [8/10], Train Loss: 0.0332, Val Acc: 97.50%\n",
            "Epoch [9/10], Train Loss: 0.0312, Val Acc: 97.50%\n",
            "Epoch [10/10], Train Loss: 0.0405, Val Acc: 97.50%\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_acc = evaluate_model(model, test_loader)\n",
        "print(f\"Test Accuracy: {test_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uScqvqAFOv2v",
        "outputId": "a3b92861-6089-40b0-e09c-34e0e60954d9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 95.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fvcore\n"
      ],
      "metadata": {
        "id": "eqZ240d7PWZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the parameters\n",
        "from torchsummary import summary\n",
        "summary(model, (3, 224, 224))  # Assuming the input size is 224x224\n",
        "\n",
        "# For FLOPs and inference time, you can use the same approach as previously shown\n",
        "import torch\n",
        "from fvcore.nn import FlopCountAnalysis\n",
        "import time\n",
        "\n",
        "# Get FLOPs\n",
        "flops = FlopCountAnalysis(model, torch.randn(1, 3, 224, 224).to(device))\n",
        "print(\"FLOPs:\", flops.total())\n",
        "\n",
        "# Test Inference time\n",
        "start_time = time.time()\n",
        "model(torch.randn(1, 3, 224, 224).to(device))  # Run inference on a random image\n",
        "inference_time = time.time() - start_time\n",
        "print(f\"Average inference time per image: {inference_time:.4f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2X4G5v3YPQ2j",
        "outputId": "3eee2701-8fec-4a92-8c4c-abd20e1d5021"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]             896\n",
            "              ReLU-2         [-1, 32, 224, 224]               0\n",
            "         MaxPool2d-3         [-1, 32, 112, 112]               0\n",
            "            Conv2d-4         [-1, 64, 112, 112]          18,496\n",
            "              ReLU-5         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-6           [-1, 64, 56, 56]               0\n",
            "            Conv2d-7          [-1, 128, 56, 56]          73,856\n",
            "              ReLU-8          [-1, 128, 56, 56]               0\n",
            "         MaxPool2d-9          [-1, 128, 28, 28]               0\n",
            "           Linear-10                  [-1, 512]      51,380,736\n",
            "             ReLU-11                  [-1, 512]               0\n",
            "           Linear-12                    [-1, 2]           1,026\n",
            "================================================================\n",
            "Total params: 51,475,010\n",
            "Trainable params: 51,475,010\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 48.24\n",
            "Params size (MB): 196.36\n",
            "Estimated Total Size (MB): 245.18\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::max_pool2d encountered 3 time(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FLOPs: 557155328\n",
            "Average inference time per image: 0.0033 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet 18"
      ],
      "metadata": {
        "id": "VbnoxcQQP8UQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet18\n",
        "\n",
        "# Load pretrained ResNet18\n",
        "resnet_model = resnet18(pretrained=True)\n",
        "\n",
        "# Modify the final layer for binary classification\n",
        "num_ftrs = resnet_model.fc.in_features\n",
        "resnet_model.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "# Move to device\n",
        "resnet_model = resnet_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxrbFvJ_P_b3",
        "outputId": "f3dd84fb-620f-47bb-f3eb-5f7e0f5405f5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 122MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(resnet_model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "U0hzIX76QBk4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    resnet_model.train()\n",
        "    train_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = resnet_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    resnet_model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = resnet_model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_acc = 100 * correct / total\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss/len(train_loader):.4f}, Val Acc: {val_acc:.2f}%')\n",
        "\n",
        "print(\"Training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDpyQjquQK8G",
        "outputId": "c6366d8e-f421-4f19-e500-aa326d73f8ab"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Train Loss: 0.1533, Val Acc: 92.50%\n",
            "Epoch [2/10], Train Loss: 0.0619, Val Acc: 97.50%\n",
            "Epoch [3/10], Train Loss: 0.0510, Val Acc: 97.50%\n",
            "Epoch [4/10], Train Loss: 0.0287, Val Acc: 97.50%\n",
            "Epoch [5/10], Train Loss: 0.0375, Val Acc: 93.75%\n",
            "Epoch [6/10], Train Loss: 0.0351, Val Acc: 100.00%\n",
            "Epoch [7/10], Train Loss: 0.0135, Val Acc: 98.75%\n",
            "Epoch [8/10], Train Loss: 0.0668, Val Acc: 97.50%\n",
            "Epoch [9/10], Train Loss: 0.0338, Val Acc: 100.00%\n",
            "Epoch [10/10], Train Loss: 0.0231, Val Acc: 98.75%\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(resnet_model, input_size=(3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9u5Q9S7QzUP",
        "outputId": "02b4047a-0ff9-47a7-8fca-3449072624da"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "             ReLU-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
            "             ReLU-17           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
            "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
            "             ReLU-21          [-1, 128, 28, 28]               0\n",
            "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
            "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
            "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
            "             ReLU-26          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
            "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
            "             ReLU-30          [-1, 128, 28, 28]               0\n",
            "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
            "             ReLU-33          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
            "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
            "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
            "             ReLU-37          [-1, 256, 14, 14]               0\n",
            "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
            "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
            "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
            "             ReLU-42          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
            "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
            "             ReLU-46          [-1, 256, 14, 14]               0\n",
            "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
            "             ReLU-49          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
            "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-53            [-1, 512, 7, 7]               0\n",
            "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
            "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-58            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
            "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-62            [-1, 512, 7, 7]               0\n",
            "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-65            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                    [-1, 2]           1,026\n",
            "================================================================\n",
            "Total params: 11,177,538\n",
            "Trainable params: 11,177,538\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 62.79\n",
            "Params size (MB): 42.64\n",
            "Estimated Total Size (MB): 106.00\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fvcore  # if not already installed\n",
        "\n",
        "from fvcore.nn import FlopCountAnalysis, parameter_count_table\n",
        "import time\n",
        "\n",
        "# FLOPs calculation\n",
        "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
        "flops = FlopCountAnalysis(resnet_model, dummy_input)\n",
        "print(\"FLOPs:\", flops.total())\n",
        "\n",
        "# Inference time per image\n",
        "start_time = time.time()\n",
        "with torch.no_grad():\n",
        "    for _ in range(100):\n",
        "        _ = resnet_model(dummy_input)\n",
        "end_time = time.time()\n",
        "\n",
        "avg_inference_time = (end_time - start_time) / 100\n",
        "print(f\"Average inference time per image: {avg_inference_time:.4f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_usmTXFQ7bN",
        "outputId": "59633f27-2039-4441-8970-08d56d9ba753"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fvcore in /usr/local/lib/python3.11/dist-packages (0.1.5.post20221221)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore) (2.0.2)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.1.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from fvcore) (4.67.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (3.0.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from fvcore) (11.1.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.9.0)\n",
            "Requirement already satisfied: iopath>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.1.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.7->fvcore) (4.13.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.7->fvcore) (3.1.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::max_pool2d encountered 1 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add_ encountered 8 time(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FLOPs: 1818554880\n",
            "Average inference time per image: 0.0030 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MobileNet V2"
      ],
      "metadata": {
        "id": "Le52OZHqRQYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
        "    train_loss_history = []\n",
        "    val_acc_history = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = running_loss / len(train_loader)\n",
        "        train_loss_history.append(avg_train_loss)\n",
        "\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_accuracy = 100 * correct / total\n",
        "        val_acc_history.append(val_accuracy)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "    return model, (train_loss_history, val_acc_history)\n"
      ],
      "metadata": {
        "id": "mpiD_dEOR-t4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "\n",
        "# Load pretrained MobileNetV2 model\n",
        "mobilenet = models.mobilenet_v2(pretrained=True)\n",
        "\n",
        "# Freeze all layers (optional)\n",
        "for param in mobilenet.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify the classifier to match the number of output classes (2: fire, nofire)\n",
        "mobilenet.classifier[1] = nn.Linear(mobilenet.last_channel, 2)\n",
        "\n",
        "# Move to device\n",
        "mobilenet = mobilenet.to(device)\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(mobilenet.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "mobilenet, history = train_model(mobilenet, train_loader, val_loader, criterion, optimizer, 10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weumrflCRTso",
        "outputId": "ca78900b-a931-4760-b643-ede435c2e813"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Train Loss: 0.2407, Val Acc: 96.25%\n",
            "Epoch [2/10], Train Loss: 0.1037, Val Acc: 98.75%\n",
            "Epoch [3/10], Train Loss: 0.0939, Val Acc: 98.75%\n",
            "Epoch [4/10], Train Loss: 0.0659, Val Acc: 98.75%\n",
            "Epoch [5/10], Train Loss: 0.0514, Val Acc: 98.75%\n",
            "Epoch [6/10], Train Loss: 0.0451, Val Acc: 98.75%\n",
            "Epoch [7/10], Train Loss: 0.0397, Val Acc: 97.50%\n",
            "Epoch [8/10], Train Loss: 0.0468, Val Acc: 98.75%\n",
            "Epoch [9/10], Train Loss: 0.0429, Val Acc: 98.75%\n",
            "Epoch [10/10], Train Loss: 0.0380, Val Acc: 97.50%\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(mobilenet, input_size=(3, 224, 224))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cdwz2hroS48Y",
        "outputId": "b36c6523-a8a1-41e0-eaf1-bb2c3458538d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 112, 112]             864\n",
            "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
            "             ReLU6-3         [-1, 32, 112, 112]               0\n",
            "            Conv2d-4         [-1, 32, 112, 112]             288\n",
            "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
            "             ReLU6-6         [-1, 32, 112, 112]               0\n",
            "            Conv2d-7         [-1, 16, 112, 112]             512\n",
            "       BatchNorm2d-8         [-1, 16, 112, 112]              32\n",
            "  InvertedResidual-9         [-1, 16, 112, 112]               0\n",
            "           Conv2d-10         [-1, 96, 112, 112]           1,536\n",
            "      BatchNorm2d-11         [-1, 96, 112, 112]             192\n",
            "            ReLU6-12         [-1, 96, 112, 112]               0\n",
            "           Conv2d-13           [-1, 96, 56, 56]             864\n",
            "      BatchNorm2d-14           [-1, 96, 56, 56]             192\n",
            "            ReLU6-15           [-1, 96, 56, 56]               0\n",
            "           Conv2d-16           [-1, 24, 56, 56]           2,304\n",
            "      BatchNorm2d-17           [-1, 24, 56, 56]              48\n",
            " InvertedResidual-18           [-1, 24, 56, 56]               0\n",
            "           Conv2d-19          [-1, 144, 56, 56]           3,456\n",
            "      BatchNorm2d-20          [-1, 144, 56, 56]             288\n",
            "            ReLU6-21          [-1, 144, 56, 56]               0\n",
            "           Conv2d-22          [-1, 144, 56, 56]           1,296\n",
            "      BatchNorm2d-23          [-1, 144, 56, 56]             288\n",
            "            ReLU6-24          [-1, 144, 56, 56]               0\n",
            "           Conv2d-25           [-1, 24, 56, 56]           3,456\n",
            "      BatchNorm2d-26           [-1, 24, 56, 56]              48\n",
            " InvertedResidual-27           [-1, 24, 56, 56]               0\n",
            "           Conv2d-28          [-1, 144, 56, 56]           3,456\n",
            "      BatchNorm2d-29          [-1, 144, 56, 56]             288\n",
            "            ReLU6-30          [-1, 144, 56, 56]               0\n",
            "           Conv2d-31          [-1, 144, 28, 28]           1,296\n",
            "      BatchNorm2d-32          [-1, 144, 28, 28]             288\n",
            "            ReLU6-33          [-1, 144, 28, 28]               0\n",
            "           Conv2d-34           [-1, 32, 28, 28]           4,608\n",
            "      BatchNorm2d-35           [-1, 32, 28, 28]              64\n",
            " InvertedResidual-36           [-1, 32, 28, 28]               0\n",
            "           Conv2d-37          [-1, 192, 28, 28]           6,144\n",
            "      BatchNorm2d-38          [-1, 192, 28, 28]             384\n",
            "            ReLU6-39          [-1, 192, 28, 28]               0\n",
            "           Conv2d-40          [-1, 192, 28, 28]           1,728\n",
            "      BatchNorm2d-41          [-1, 192, 28, 28]             384\n",
            "            ReLU6-42          [-1, 192, 28, 28]               0\n",
            "           Conv2d-43           [-1, 32, 28, 28]           6,144\n",
            "      BatchNorm2d-44           [-1, 32, 28, 28]              64\n",
            " InvertedResidual-45           [-1, 32, 28, 28]               0\n",
            "           Conv2d-46          [-1, 192, 28, 28]           6,144\n",
            "      BatchNorm2d-47          [-1, 192, 28, 28]             384\n",
            "            ReLU6-48          [-1, 192, 28, 28]               0\n",
            "           Conv2d-49          [-1, 192, 28, 28]           1,728\n",
            "      BatchNorm2d-50          [-1, 192, 28, 28]             384\n",
            "            ReLU6-51          [-1, 192, 28, 28]               0\n",
            "           Conv2d-52           [-1, 32, 28, 28]           6,144\n",
            "      BatchNorm2d-53           [-1, 32, 28, 28]              64\n",
            " InvertedResidual-54           [-1, 32, 28, 28]               0\n",
            "           Conv2d-55          [-1, 192, 28, 28]           6,144\n",
            "      BatchNorm2d-56          [-1, 192, 28, 28]             384\n",
            "            ReLU6-57          [-1, 192, 28, 28]               0\n",
            "           Conv2d-58          [-1, 192, 14, 14]           1,728\n",
            "      BatchNorm2d-59          [-1, 192, 14, 14]             384\n",
            "            ReLU6-60          [-1, 192, 14, 14]               0\n",
            "           Conv2d-61           [-1, 64, 14, 14]          12,288\n",
            "      BatchNorm2d-62           [-1, 64, 14, 14]             128\n",
            " InvertedResidual-63           [-1, 64, 14, 14]               0\n",
            "           Conv2d-64          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-65          [-1, 384, 14, 14]             768\n",
            "            ReLU6-66          [-1, 384, 14, 14]               0\n",
            "           Conv2d-67          [-1, 384, 14, 14]           3,456\n",
            "      BatchNorm2d-68          [-1, 384, 14, 14]             768\n",
            "            ReLU6-69          [-1, 384, 14, 14]               0\n",
            "           Conv2d-70           [-1, 64, 14, 14]          24,576\n",
            "      BatchNorm2d-71           [-1, 64, 14, 14]             128\n",
            " InvertedResidual-72           [-1, 64, 14, 14]               0\n",
            "           Conv2d-73          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-74          [-1, 384, 14, 14]             768\n",
            "            ReLU6-75          [-1, 384, 14, 14]               0\n",
            "           Conv2d-76          [-1, 384, 14, 14]           3,456\n",
            "      BatchNorm2d-77          [-1, 384, 14, 14]             768\n",
            "            ReLU6-78          [-1, 384, 14, 14]               0\n",
            "           Conv2d-79           [-1, 64, 14, 14]          24,576\n",
            "      BatchNorm2d-80           [-1, 64, 14, 14]             128\n",
            " InvertedResidual-81           [-1, 64, 14, 14]               0\n",
            "           Conv2d-82          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-83          [-1, 384, 14, 14]             768\n",
            "            ReLU6-84          [-1, 384, 14, 14]               0\n",
            "           Conv2d-85          [-1, 384, 14, 14]           3,456\n",
            "      BatchNorm2d-86          [-1, 384, 14, 14]             768\n",
            "            ReLU6-87          [-1, 384, 14, 14]               0\n",
            "           Conv2d-88           [-1, 64, 14, 14]          24,576\n",
            "      BatchNorm2d-89           [-1, 64, 14, 14]             128\n",
            " InvertedResidual-90           [-1, 64, 14, 14]               0\n",
            "           Conv2d-91          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-92          [-1, 384, 14, 14]             768\n",
            "            ReLU6-93          [-1, 384, 14, 14]               0\n",
            "           Conv2d-94          [-1, 384, 14, 14]           3,456\n",
            "      BatchNorm2d-95          [-1, 384, 14, 14]             768\n",
            "            ReLU6-96          [-1, 384, 14, 14]               0\n",
            "           Conv2d-97           [-1, 96, 14, 14]          36,864\n",
            "      BatchNorm2d-98           [-1, 96, 14, 14]             192\n",
            " InvertedResidual-99           [-1, 96, 14, 14]               0\n",
            "          Conv2d-100          [-1, 576, 14, 14]          55,296\n",
            "     BatchNorm2d-101          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-102          [-1, 576, 14, 14]               0\n",
            "          Conv2d-103          [-1, 576, 14, 14]           5,184\n",
            "     BatchNorm2d-104          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-105          [-1, 576, 14, 14]               0\n",
            "          Conv2d-106           [-1, 96, 14, 14]          55,296\n",
            "     BatchNorm2d-107           [-1, 96, 14, 14]             192\n",
            "InvertedResidual-108           [-1, 96, 14, 14]               0\n",
            "          Conv2d-109          [-1, 576, 14, 14]          55,296\n",
            "     BatchNorm2d-110          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-111          [-1, 576, 14, 14]               0\n",
            "          Conv2d-112          [-1, 576, 14, 14]           5,184\n",
            "     BatchNorm2d-113          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-114          [-1, 576, 14, 14]               0\n",
            "          Conv2d-115           [-1, 96, 14, 14]          55,296\n",
            "     BatchNorm2d-116           [-1, 96, 14, 14]             192\n",
            "InvertedResidual-117           [-1, 96, 14, 14]               0\n",
            "          Conv2d-118          [-1, 576, 14, 14]          55,296\n",
            "     BatchNorm2d-119          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-120          [-1, 576, 14, 14]               0\n",
            "          Conv2d-121            [-1, 576, 7, 7]           5,184\n",
            "     BatchNorm2d-122            [-1, 576, 7, 7]           1,152\n",
            "           ReLU6-123            [-1, 576, 7, 7]               0\n",
            "          Conv2d-124            [-1, 160, 7, 7]          92,160\n",
            "     BatchNorm2d-125            [-1, 160, 7, 7]             320\n",
            "InvertedResidual-126            [-1, 160, 7, 7]               0\n",
            "          Conv2d-127            [-1, 960, 7, 7]         153,600\n",
            "     BatchNorm2d-128            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-129            [-1, 960, 7, 7]               0\n",
            "          Conv2d-130            [-1, 960, 7, 7]           8,640\n",
            "     BatchNorm2d-131            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-132            [-1, 960, 7, 7]               0\n",
            "          Conv2d-133            [-1, 160, 7, 7]         153,600\n",
            "     BatchNorm2d-134            [-1, 160, 7, 7]             320\n",
            "InvertedResidual-135            [-1, 160, 7, 7]               0\n",
            "          Conv2d-136            [-1, 960, 7, 7]         153,600\n",
            "     BatchNorm2d-137            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-138            [-1, 960, 7, 7]               0\n",
            "          Conv2d-139            [-1, 960, 7, 7]           8,640\n",
            "     BatchNorm2d-140            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-141            [-1, 960, 7, 7]               0\n",
            "          Conv2d-142            [-1, 160, 7, 7]         153,600\n",
            "     BatchNorm2d-143            [-1, 160, 7, 7]             320\n",
            "InvertedResidual-144            [-1, 160, 7, 7]               0\n",
            "          Conv2d-145            [-1, 960, 7, 7]         153,600\n",
            "     BatchNorm2d-146            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-147            [-1, 960, 7, 7]               0\n",
            "          Conv2d-148            [-1, 960, 7, 7]           8,640\n",
            "     BatchNorm2d-149            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-150            [-1, 960, 7, 7]               0\n",
            "          Conv2d-151            [-1, 320, 7, 7]         307,200\n",
            "     BatchNorm2d-152            [-1, 320, 7, 7]             640\n",
            "InvertedResidual-153            [-1, 320, 7, 7]               0\n",
            "          Conv2d-154           [-1, 1280, 7, 7]         409,600\n",
            "     BatchNorm2d-155           [-1, 1280, 7, 7]           2,560\n",
            "           ReLU6-156           [-1, 1280, 7, 7]               0\n",
            "         Dropout-157                 [-1, 1280]               0\n",
            "          Linear-158                    [-1, 2]           2,562\n",
            "================================================================\n",
            "Total params: 2,226,434\n",
            "Trainable params: 2,562\n",
            "Non-trainable params: 2,223,872\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 152.86\n",
            "Params size (MB): 8.49\n",
            "Estimated Total Size (MB): 161.93\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fvcore.nn import FlopCountAnalysis\n",
        "\n",
        "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
        "flops = FlopCountAnalysis(mobilenet, dummy_input)\n",
        "print(f\"FLOPs: {flops.total()}\")  # Or use flops.pretty_print() for formatted\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XGdKJv_S7ID",
        "outputId": "d259f314-4c32-41e9-acd4-0f239447d68a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::hardtanh_ encountered 35 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add encountered 10 time(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FLOPs: 312915776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "mobilenet.eval()\n",
        "start_time = time.time()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for _ in range(100):\n",
        "        _ = mobilenet(dummy_input)\n",
        "\n",
        "end_time = time.time()\n",
        "avg_inference_time = (end_time - start_time) / 100\n",
        "print(f\"Average inference time per image: {avg_inference_time:.4f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8MAvoWiS_-c",
        "outputId": "0157b4fd-21f8-4091-c127-40fe6d35c6e8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average inference time per image: 0.0056 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EfficentNetB0"
      ],
      "metadata": {
        "id": "WotNJA6qTbJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "import torch.optim as optim\n",
        "\n",
        "# Load the EfficientNetB0 model\n",
        "efficientnet = models.efficientnet_b0(pretrained=True)\n",
        "efficientnet.classifier[1] = torch.nn.Linear(efficientnet.classifier[1].in_features, 2)  # Adjust for 2 output classes\n",
        "\n",
        "# Send the model to the device\n",
        "efficientnet = efficientnet.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(efficientnet.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "efficientnet, history = train_model(efficientnet, train_loader, val_loader, criterion, optimizer, 10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2BTEKbrTdIm",
        "outputId": "00d1b4cd-f7c7-45ee-cf82-2dd0fc0ef7e6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 144MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Train Loss: 0.1035, Val Acc: 100.00%\n",
            "Epoch [2/10], Train Loss: 0.0402, Val Acc: 100.00%\n",
            "Epoch [3/10], Train Loss: 0.0296, Val Acc: 100.00%\n",
            "Epoch [4/10], Train Loss: 0.0154, Val Acc: 98.75%\n",
            "Epoch [5/10], Train Loss: 0.0224, Val Acc: 100.00%\n",
            "Epoch [6/10], Train Loss: 0.0255, Val Acc: 100.00%\n",
            "Epoch [7/10], Train Loss: 0.0140, Val Acc: 100.00%\n",
            "Epoch [8/10], Train Loss: 0.0344, Val Acc: 98.75%\n",
            "Epoch [9/10], Train Loss: 0.0168, Val Acc: 100.00%\n",
            "Epoch [10/10], Train Loss: 0.0231, Val Acc: 100.00%\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(efficientnet, (3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvSnIXnmTe4P",
        "outputId": "e19cf7c2-8292-46d7-9b43-1013e521fe9c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 112, 112]             864\n",
            "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
            "              SiLU-3         [-1, 32, 112, 112]               0\n",
            "            Conv2d-4         [-1, 32, 112, 112]             288\n",
            "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
            "              SiLU-6         [-1, 32, 112, 112]               0\n",
            " AdaptiveAvgPool2d-7             [-1, 32, 1, 1]               0\n",
            "            Conv2d-8              [-1, 8, 1, 1]             264\n",
            "              SiLU-9              [-1, 8, 1, 1]               0\n",
            "           Conv2d-10             [-1, 32, 1, 1]             288\n",
            "          Sigmoid-11             [-1, 32, 1, 1]               0\n",
            "SqueezeExcitation-12         [-1, 32, 112, 112]               0\n",
            "           Conv2d-13         [-1, 16, 112, 112]             512\n",
            "      BatchNorm2d-14         [-1, 16, 112, 112]              32\n",
            "           MBConv-15         [-1, 16, 112, 112]               0\n",
            "           Conv2d-16         [-1, 96, 112, 112]           1,536\n",
            "      BatchNorm2d-17         [-1, 96, 112, 112]             192\n",
            "             SiLU-18         [-1, 96, 112, 112]               0\n",
            "           Conv2d-19           [-1, 96, 56, 56]             864\n",
            "      BatchNorm2d-20           [-1, 96, 56, 56]             192\n",
            "             SiLU-21           [-1, 96, 56, 56]               0\n",
            "AdaptiveAvgPool2d-22             [-1, 96, 1, 1]               0\n",
            "           Conv2d-23              [-1, 4, 1, 1]             388\n",
            "             SiLU-24              [-1, 4, 1, 1]               0\n",
            "           Conv2d-25             [-1, 96, 1, 1]             480\n",
            "          Sigmoid-26             [-1, 96, 1, 1]               0\n",
            "SqueezeExcitation-27           [-1, 96, 56, 56]               0\n",
            "           Conv2d-28           [-1, 24, 56, 56]           2,304\n",
            "      BatchNorm2d-29           [-1, 24, 56, 56]              48\n",
            "           MBConv-30           [-1, 24, 56, 56]               0\n",
            "           Conv2d-31          [-1, 144, 56, 56]           3,456\n",
            "      BatchNorm2d-32          [-1, 144, 56, 56]             288\n",
            "             SiLU-33          [-1, 144, 56, 56]               0\n",
            "           Conv2d-34          [-1, 144, 56, 56]           1,296\n",
            "      BatchNorm2d-35          [-1, 144, 56, 56]             288\n",
            "             SiLU-36          [-1, 144, 56, 56]               0\n",
            "AdaptiveAvgPool2d-37            [-1, 144, 1, 1]               0\n",
            "           Conv2d-38              [-1, 6, 1, 1]             870\n",
            "             SiLU-39              [-1, 6, 1, 1]               0\n",
            "           Conv2d-40            [-1, 144, 1, 1]           1,008\n",
            "          Sigmoid-41            [-1, 144, 1, 1]               0\n",
            "SqueezeExcitation-42          [-1, 144, 56, 56]               0\n",
            "           Conv2d-43           [-1, 24, 56, 56]           3,456\n",
            "      BatchNorm2d-44           [-1, 24, 56, 56]              48\n",
            "  StochasticDepth-45           [-1, 24, 56, 56]               0\n",
            "           MBConv-46           [-1, 24, 56, 56]               0\n",
            "           Conv2d-47          [-1, 144, 56, 56]           3,456\n",
            "      BatchNorm2d-48          [-1, 144, 56, 56]             288\n",
            "             SiLU-49          [-1, 144, 56, 56]               0\n",
            "           Conv2d-50          [-1, 144, 28, 28]           3,600\n",
            "      BatchNorm2d-51          [-1, 144, 28, 28]             288\n",
            "             SiLU-52          [-1, 144, 28, 28]               0\n",
            "AdaptiveAvgPool2d-53            [-1, 144, 1, 1]               0\n",
            "           Conv2d-54              [-1, 6, 1, 1]             870\n",
            "             SiLU-55              [-1, 6, 1, 1]               0\n",
            "           Conv2d-56            [-1, 144, 1, 1]           1,008\n",
            "          Sigmoid-57            [-1, 144, 1, 1]               0\n",
            "SqueezeExcitation-58          [-1, 144, 28, 28]               0\n",
            "           Conv2d-59           [-1, 40, 28, 28]           5,760\n",
            "      BatchNorm2d-60           [-1, 40, 28, 28]              80\n",
            "           MBConv-61           [-1, 40, 28, 28]               0\n",
            "           Conv2d-62          [-1, 240, 28, 28]           9,600\n",
            "      BatchNorm2d-63          [-1, 240, 28, 28]             480\n",
            "             SiLU-64          [-1, 240, 28, 28]               0\n",
            "           Conv2d-65          [-1, 240, 28, 28]           6,000\n",
            "      BatchNorm2d-66          [-1, 240, 28, 28]             480\n",
            "             SiLU-67          [-1, 240, 28, 28]               0\n",
            "AdaptiveAvgPool2d-68            [-1, 240, 1, 1]               0\n",
            "           Conv2d-69             [-1, 10, 1, 1]           2,410\n",
            "             SiLU-70             [-1, 10, 1, 1]               0\n",
            "           Conv2d-71            [-1, 240, 1, 1]           2,640\n",
            "          Sigmoid-72            [-1, 240, 1, 1]               0\n",
            "SqueezeExcitation-73          [-1, 240, 28, 28]               0\n",
            "           Conv2d-74           [-1, 40, 28, 28]           9,600\n",
            "      BatchNorm2d-75           [-1, 40, 28, 28]              80\n",
            "  StochasticDepth-76           [-1, 40, 28, 28]               0\n",
            "           MBConv-77           [-1, 40, 28, 28]               0\n",
            "           Conv2d-78          [-1, 240, 28, 28]           9,600\n",
            "      BatchNorm2d-79          [-1, 240, 28, 28]             480\n",
            "             SiLU-80          [-1, 240, 28, 28]               0\n",
            "           Conv2d-81          [-1, 240, 14, 14]           2,160\n",
            "      BatchNorm2d-82          [-1, 240, 14, 14]             480\n",
            "             SiLU-83          [-1, 240, 14, 14]               0\n",
            "AdaptiveAvgPool2d-84            [-1, 240, 1, 1]               0\n",
            "           Conv2d-85             [-1, 10, 1, 1]           2,410\n",
            "             SiLU-86             [-1, 10, 1, 1]               0\n",
            "           Conv2d-87            [-1, 240, 1, 1]           2,640\n",
            "          Sigmoid-88            [-1, 240, 1, 1]               0\n",
            "SqueezeExcitation-89          [-1, 240, 14, 14]               0\n",
            "           Conv2d-90           [-1, 80, 14, 14]          19,200\n",
            "      BatchNorm2d-91           [-1, 80, 14, 14]             160\n",
            "           MBConv-92           [-1, 80, 14, 14]               0\n",
            "           Conv2d-93          [-1, 480, 14, 14]          38,400\n",
            "      BatchNorm2d-94          [-1, 480, 14, 14]             960\n",
            "             SiLU-95          [-1, 480, 14, 14]               0\n",
            "           Conv2d-96          [-1, 480, 14, 14]           4,320\n",
            "      BatchNorm2d-97          [-1, 480, 14, 14]             960\n",
            "             SiLU-98          [-1, 480, 14, 14]               0\n",
            "AdaptiveAvgPool2d-99            [-1, 480, 1, 1]               0\n",
            "          Conv2d-100             [-1, 20, 1, 1]           9,620\n",
            "            SiLU-101             [-1, 20, 1, 1]               0\n",
            "          Conv2d-102            [-1, 480, 1, 1]          10,080\n",
            "         Sigmoid-103            [-1, 480, 1, 1]               0\n",
            "SqueezeExcitation-104          [-1, 480, 14, 14]               0\n",
            "          Conv2d-105           [-1, 80, 14, 14]          38,400\n",
            "     BatchNorm2d-106           [-1, 80, 14, 14]             160\n",
            " StochasticDepth-107           [-1, 80, 14, 14]               0\n",
            "          MBConv-108           [-1, 80, 14, 14]               0\n",
            "          Conv2d-109          [-1, 480, 14, 14]          38,400\n",
            "     BatchNorm2d-110          [-1, 480, 14, 14]             960\n",
            "            SiLU-111          [-1, 480, 14, 14]               0\n",
            "          Conv2d-112          [-1, 480, 14, 14]           4,320\n",
            "     BatchNorm2d-113          [-1, 480, 14, 14]             960\n",
            "            SiLU-114          [-1, 480, 14, 14]               0\n",
            "AdaptiveAvgPool2d-115            [-1, 480, 1, 1]               0\n",
            "          Conv2d-116             [-1, 20, 1, 1]           9,620\n",
            "            SiLU-117             [-1, 20, 1, 1]               0\n",
            "          Conv2d-118            [-1, 480, 1, 1]          10,080\n",
            "         Sigmoid-119            [-1, 480, 1, 1]               0\n",
            "SqueezeExcitation-120          [-1, 480, 14, 14]               0\n",
            "          Conv2d-121           [-1, 80, 14, 14]          38,400\n",
            "     BatchNorm2d-122           [-1, 80, 14, 14]             160\n",
            " StochasticDepth-123           [-1, 80, 14, 14]               0\n",
            "          MBConv-124           [-1, 80, 14, 14]               0\n",
            "          Conv2d-125          [-1, 480, 14, 14]          38,400\n",
            "     BatchNorm2d-126          [-1, 480, 14, 14]             960\n",
            "            SiLU-127          [-1, 480, 14, 14]               0\n",
            "          Conv2d-128          [-1, 480, 14, 14]          12,000\n",
            "     BatchNorm2d-129          [-1, 480, 14, 14]             960\n",
            "            SiLU-130          [-1, 480, 14, 14]               0\n",
            "AdaptiveAvgPool2d-131            [-1, 480, 1, 1]               0\n",
            "          Conv2d-132             [-1, 20, 1, 1]           9,620\n",
            "            SiLU-133             [-1, 20, 1, 1]               0\n",
            "          Conv2d-134            [-1, 480, 1, 1]          10,080\n",
            "         Sigmoid-135            [-1, 480, 1, 1]               0\n",
            "SqueezeExcitation-136          [-1, 480, 14, 14]               0\n",
            "          Conv2d-137          [-1, 112, 14, 14]          53,760\n",
            "     BatchNorm2d-138          [-1, 112, 14, 14]             224\n",
            "          MBConv-139          [-1, 112, 14, 14]               0\n",
            "          Conv2d-140          [-1, 672, 14, 14]          75,264\n",
            "     BatchNorm2d-141          [-1, 672, 14, 14]           1,344\n",
            "            SiLU-142          [-1, 672, 14, 14]               0\n",
            "          Conv2d-143          [-1, 672, 14, 14]          16,800\n",
            "     BatchNorm2d-144          [-1, 672, 14, 14]           1,344\n",
            "            SiLU-145          [-1, 672, 14, 14]               0\n",
            "AdaptiveAvgPool2d-146            [-1, 672, 1, 1]               0\n",
            "          Conv2d-147             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-148             [-1, 28, 1, 1]               0\n",
            "          Conv2d-149            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-150            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-151          [-1, 672, 14, 14]               0\n",
            "          Conv2d-152          [-1, 112, 14, 14]          75,264\n",
            "     BatchNorm2d-153          [-1, 112, 14, 14]             224\n",
            " StochasticDepth-154          [-1, 112, 14, 14]               0\n",
            "          MBConv-155          [-1, 112, 14, 14]               0\n",
            "          Conv2d-156          [-1, 672, 14, 14]          75,264\n",
            "     BatchNorm2d-157          [-1, 672, 14, 14]           1,344\n",
            "            SiLU-158          [-1, 672, 14, 14]               0\n",
            "          Conv2d-159          [-1, 672, 14, 14]          16,800\n",
            "     BatchNorm2d-160          [-1, 672, 14, 14]           1,344\n",
            "            SiLU-161          [-1, 672, 14, 14]               0\n",
            "AdaptiveAvgPool2d-162            [-1, 672, 1, 1]               0\n",
            "          Conv2d-163             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-164             [-1, 28, 1, 1]               0\n",
            "          Conv2d-165            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-166            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-167          [-1, 672, 14, 14]               0\n",
            "          Conv2d-168          [-1, 112, 14, 14]          75,264\n",
            "     BatchNorm2d-169          [-1, 112, 14, 14]             224\n",
            " StochasticDepth-170          [-1, 112, 14, 14]               0\n",
            "          MBConv-171          [-1, 112, 14, 14]               0\n",
            "          Conv2d-172          [-1, 672, 14, 14]          75,264\n",
            "     BatchNorm2d-173          [-1, 672, 14, 14]           1,344\n",
            "            SiLU-174          [-1, 672, 14, 14]               0\n",
            "          Conv2d-175            [-1, 672, 7, 7]          16,800\n",
            "     BatchNorm2d-176            [-1, 672, 7, 7]           1,344\n",
            "            SiLU-177            [-1, 672, 7, 7]               0\n",
            "AdaptiveAvgPool2d-178            [-1, 672, 1, 1]               0\n",
            "          Conv2d-179             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-180             [-1, 28, 1, 1]               0\n",
            "          Conv2d-181            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-182            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-183            [-1, 672, 7, 7]               0\n",
            "          Conv2d-184            [-1, 192, 7, 7]         129,024\n",
            "     BatchNorm2d-185            [-1, 192, 7, 7]             384\n",
            "          MBConv-186            [-1, 192, 7, 7]               0\n",
            "          Conv2d-187           [-1, 1152, 7, 7]         221,184\n",
            "     BatchNorm2d-188           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-189           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-190           [-1, 1152, 7, 7]          28,800\n",
            "     BatchNorm2d-191           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-192           [-1, 1152, 7, 7]               0\n",
            "AdaptiveAvgPool2d-193           [-1, 1152, 1, 1]               0\n",
            "          Conv2d-194             [-1, 48, 1, 1]          55,344\n",
            "            SiLU-195             [-1, 48, 1, 1]               0\n",
            "          Conv2d-196           [-1, 1152, 1, 1]          56,448\n",
            "         Sigmoid-197           [-1, 1152, 1, 1]               0\n",
            "SqueezeExcitation-198           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-199            [-1, 192, 7, 7]         221,184\n",
            "     BatchNorm2d-200            [-1, 192, 7, 7]             384\n",
            " StochasticDepth-201            [-1, 192, 7, 7]               0\n",
            "          MBConv-202            [-1, 192, 7, 7]               0\n",
            "          Conv2d-203           [-1, 1152, 7, 7]         221,184\n",
            "     BatchNorm2d-204           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-205           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-206           [-1, 1152, 7, 7]          28,800\n",
            "     BatchNorm2d-207           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-208           [-1, 1152, 7, 7]               0\n",
            "AdaptiveAvgPool2d-209           [-1, 1152, 1, 1]               0\n",
            "          Conv2d-210             [-1, 48, 1, 1]          55,344\n",
            "            SiLU-211             [-1, 48, 1, 1]               0\n",
            "          Conv2d-212           [-1, 1152, 1, 1]          56,448\n",
            "         Sigmoid-213           [-1, 1152, 1, 1]               0\n",
            "SqueezeExcitation-214           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-215            [-1, 192, 7, 7]         221,184\n",
            "     BatchNorm2d-216            [-1, 192, 7, 7]             384\n",
            " StochasticDepth-217            [-1, 192, 7, 7]               0\n",
            "          MBConv-218            [-1, 192, 7, 7]               0\n",
            "          Conv2d-219           [-1, 1152, 7, 7]         221,184\n",
            "     BatchNorm2d-220           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-221           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-222           [-1, 1152, 7, 7]          28,800\n",
            "     BatchNorm2d-223           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-224           [-1, 1152, 7, 7]               0\n",
            "AdaptiveAvgPool2d-225           [-1, 1152, 1, 1]               0\n",
            "          Conv2d-226             [-1, 48, 1, 1]          55,344\n",
            "            SiLU-227             [-1, 48, 1, 1]               0\n",
            "          Conv2d-228           [-1, 1152, 1, 1]          56,448\n",
            "         Sigmoid-229           [-1, 1152, 1, 1]               0\n",
            "SqueezeExcitation-230           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-231            [-1, 192, 7, 7]         221,184\n",
            "     BatchNorm2d-232            [-1, 192, 7, 7]             384\n",
            " StochasticDepth-233            [-1, 192, 7, 7]               0\n",
            "          MBConv-234            [-1, 192, 7, 7]               0\n",
            "          Conv2d-235           [-1, 1152, 7, 7]         221,184\n",
            "     BatchNorm2d-236           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-237           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-238           [-1, 1152, 7, 7]          10,368\n",
            "     BatchNorm2d-239           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-240           [-1, 1152, 7, 7]               0\n",
            "AdaptiveAvgPool2d-241           [-1, 1152, 1, 1]               0\n",
            "          Conv2d-242             [-1, 48, 1, 1]          55,344\n",
            "            SiLU-243             [-1, 48, 1, 1]               0\n",
            "          Conv2d-244           [-1, 1152, 1, 1]          56,448\n",
            "         Sigmoid-245           [-1, 1152, 1, 1]               0\n",
            "SqueezeExcitation-246           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-247            [-1, 320, 7, 7]         368,640\n",
            "     BatchNorm2d-248            [-1, 320, 7, 7]             640\n",
            "          MBConv-249            [-1, 320, 7, 7]               0\n",
            "          Conv2d-250           [-1, 1280, 7, 7]         409,600\n",
            "     BatchNorm2d-251           [-1, 1280, 7, 7]           2,560\n",
            "            SiLU-252           [-1, 1280, 7, 7]               0\n",
            "AdaptiveAvgPool2d-253           [-1, 1280, 1, 1]               0\n",
            "         Dropout-254                 [-1, 1280]               0\n",
            "          Linear-255                    [-1, 2]           2,562\n",
            "================================================================\n",
            "Total params: 4,010,110\n",
            "Trainable params: 4,010,110\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 173.64\n",
            "Params size (MB): 15.30\n",
            "Estimated Total Size (MB): 189.52\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "from fvcore.nn import FlopCountAnalysis\n",
        "\n",
        "# Move model to device\n",
        "efficientnet = efficientnet.to(device)\n",
        "\n",
        "# Create a dummy input\n",
        "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
        "\n",
        "# Calculate FLOPs\n",
        "flops = FlopCountAnalysis(efficientnet, dummy_input)\n",
        "print(f\"FLOPs: {flops.total()}\")\n",
        "\n",
        "# Measure inference time\n",
        "start_time = time.time()\n",
        "with torch.no_grad():\n",
        "    efficientnet(dummy_input)\n",
        "end_time = time.time()\n",
        "\n",
        "inference_time = end_time - start_time\n",
        "print(f\"Average inference time per image: {inference_time:.4f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AXvW1dUUXLj",
        "outputId": "cac3dc57-a0f6-41b1-ff8b-f51fe3939a09"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::silu_ encountered 49 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::sigmoid encountered 16 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::mul encountered 16 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add_ encountered 9 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::dropout_ encountered 1 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
            "features.1.0.stochastic_depth, features.2.0.stochastic_depth, features.2.1.stochastic_depth, features.3.0.stochastic_depth, features.3.1.stochastic_depth, features.4.0.stochastic_depth, features.4.1.stochastic_depth, features.4.2.stochastic_depth, features.5.0.stochastic_depth, features.5.1.stochastic_depth, features.5.2.stochastic_depth, features.6.0.stochastic_depth, features.6.1.stochastic_depth, features.6.2.stochastic_depth, features.6.3.stochastic_depth, features.7.0.stochastic_depth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FLOPs: 400381952\n",
            "Average inference time per image: 0.0135 seconds\n"
          ]
        }
      ]
    }
  ]
}