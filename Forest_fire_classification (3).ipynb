{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6CwUIE9Pu_nZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "D_xsnqzEnwnp"
      },
      "outputs": [],
      "source": [
        "fire_dataset_path = '/content/drive/MyDrive/Forest Fire Project/Datasets/FIRE Dataset'\n",
        "wildfire_dataset_path = '/content/drive/MyDrive/Forest Fire Project/Datasets/Wildfire Detection Image Data'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "import time\n",
        "import onnx"
      ],
      "metadata": {
        "id": "mNo70uVN4Pup"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define image transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)  # Normalize to [-1, 1]\n",
        "])\n",
        "\n",
        "# Load FIRE Dataset\n",
        "fire_train = datasets.ImageFolder(root=f\"{fire_dataset_path}/train\", transform=transform)\n",
        "fire_val = datasets.ImageFolder(root=f\"{fire_dataset_path}/val\", transform=transform)\n",
        "fire_test = datasets.ImageFolder(root=f\"{fire_dataset_path}/test\", transform=transform)\n",
        "\n",
        "# Load Wildfire Dataset\n",
        "wildfire_train = datasets.ImageFolder(root=f\"{wildfire_dataset_path}/train\", transform=transform)\n",
        "wildfire_val = datasets.ImageFolder(root=f\"{wildfire_dataset_path}/val\", transform=transform)\n",
        "wildfire_test = datasets.ImageFolder(root=f\"{wildfire_dataset_path}/test\", transform=transform)\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 32\n",
        "\n",
        "fire_train_loader = DataLoader(fire_train, batch_size=batch_size, shuffle=True)\n",
        "fire_val_loader = DataLoader(fire_val, batch_size=batch_size, shuffle=False)\n",
        "fire_test_loader = DataLoader(fire_test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "wildfire_train_loader = DataLoader(wildfire_train, batch_size=batch_size, shuffle=True)\n",
        "wildfire_val_loader = DataLoader(wildfire_val, batch_size=batch_size, shuffle=False)\n",
        "wildfire_test_loader = DataLoader(wildfire_test, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "pipXRfJEvKdn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom 3 layer CNN model"
      ],
      "metadata": {
        "id": "e8RIwZjDvv9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, 2)  # Binary classification (fire or not)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # [B, 16, 112, 112]\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # [B, 32, 56, 56]\n",
        "        x = self.pool(F.relu(self.conv3(x)))  # [B, 64, 28, 28]\n",
        "        x = x.view(-1, 64 * 28 * 28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "E5aNEm6Qvuxw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CustomCNN().to(device)\n",
        "\n",
        "summary(model, (3, 224, 224))  # Shows parameters, shapes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1umEDmPJv6H1",
        "outputId": "e3cac21e-0582-4f76-fbdb-8fec40b991ec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 16, 224, 224]             448\n",
            "         MaxPool2d-2         [-1, 16, 112, 112]               0\n",
            "            Conv2d-3         [-1, 32, 112, 112]           4,640\n",
            "         MaxPool2d-4           [-1, 32, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          18,496\n",
            "         MaxPool2d-6           [-1, 64, 28, 28]               0\n",
            "            Linear-7                  [-1, 128]       6,422,656\n",
            "            Linear-8                    [-1, 2]             258\n",
            "================================================================\n",
            "Total params: 6,446,498\n",
            "Trainable params: 6,446,498\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 13.40\n",
            "Params size (MB): 24.59\n",
            "Estimated Total Size (MB): 38.57\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "def train_model(model, train_loader, val_loader, epochs=10, lr=0.001):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
        "        for inputs, labels in loop:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            loop.set_postfix(loss=loss.item(), acc=100. * correct / total)\n",
        "\n",
        "        val_acc = evaluate_model(model, val_loader)\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {running_loss/len(train_loader):.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "    return model\n",
        "\n",
        "\n",
        "def evaluate_model(model, loader):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    return 100 * correct / total\n"
      ],
      "metadata": {
        "id": "dJfnKALbwLGY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomCNN()\n",
        "trained_model = train_model(model, fire_train_loader, fire_val_loader, epochs=10, lr=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0ErJS0LwOMm",
        "outputId": "df77b15b-1728-4309-de9d-898d398a21f4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Train Loss: 0.3576, Val Acc: 88.75%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Train Loss: 0.1568, Val Acc: 91.25%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Train Loss: 0.1263, Val Acc: 91.25%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Train Loss: 0.0772, Val Acc: 97.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Train Loss: 0.0443, Val Acc: 95.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Train Loss: 0.0348, Val Acc: 97.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Train Loss: 0.0151, Val Acc: 96.25%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Train Loss: 0.0079, Val Acc: 97.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Train Loss: 0.0037, Val Acc: 95.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Train Loss: 0.0015, Val Acc: 96.25%\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy = evaluate_model(trained_model, fire_test_loader)\n",
        "print(f\"🔥 Test Accuracy on FIRE Dataset: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLERxBxxz7sK",
        "outputId": "5fa56a74-f648-427b-9a4d-616e7a0da3e1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔥 Test Accuracy on FIRE Dataset: 95.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ptflops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCzswWKf0XEc",
        "outputId": "ce453afe-bb14-4602-beee-52b58e8078f6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ptflops\n",
            "  Downloading ptflops-0.7.4-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from ptflops) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0->ptflops)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0->ptflops)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0->ptflops)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0->ptflops)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0->ptflops)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0->ptflops)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0->ptflops)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0->ptflops)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0->ptflops)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0->ptflops)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->ptflops) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->ptflops) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->ptflops) (3.0.2)\n",
            "Downloading ptflops-0.7.4-py3-none-any.whl (19 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ptflops\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ptflops-0.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ptflops import get_model_complexity_info\n",
        "\n",
        "with torch.cuda.device(0):\n",
        "    macs, params = get_model_complexity_info(CustomCNN(), (3, 224, 224), as_strings=True,\n",
        "                                             print_per_layer_stat=True, verbose=True)\n",
        "    print(f'FLOPs: {macs}')\n",
        "    print(f'Params: {params}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jg1n4JyA0U24",
        "outputId": "99416164-25ef-4a73-b6ce-b3bbdedcdfab"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: module CustomCNN is treated as a zero-op.\n",
            "CustomCNN(\n",
            "  6.45 M, 100.000% Params, 146.51 MMac, 98.118% MACs, \n",
            "  (conv1): Conv2d(448, 0.007% Params, 22.48 MMac, 15.054% MACs, 3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(4.64 k, 0.072% Params, 58.2 MMac, 38.978% MACs, 16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(18.5 k, 0.287% Params, 58.0 MMac, 38.844% MACs, 32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(0, 0.000% Params, 1.4 MMac, 0.941% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(6.42 M, 99.630% Params, 6.42 MMac, 4.301% MACs, in_features=50176, out_features=128, bias=True)\n",
            "  (fc2): Linear(258, 0.004% Params, 258.0 Mac, 0.000% MACs, in_features=128, out_features=2, bias=True)\n",
            ")\n",
            "FLOPs: 149.32 MMac\n",
            "Params: 6.45 M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mqSHGw41H2U",
        "outputId": "983312cb-901d-4b67-a6f4-aa8eb9f481ba"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = trained_model.to(device).eval()\n",
        "dummy_input = torch.randn(1, 3, 224, 224).to(device)"
      ],
      "metadata": {
        "id": "MvUPgoFo1Plo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Warm-up\n",
        "for _ in range(10):\n",
        "    _ = model(dummy_input)\n",
        "\n",
        "# Measure\n",
        "import time\n",
        "start = time.time()\n",
        "for _ in range(100):\n",
        "    _ = model(dummy_input)\n",
        "end = time.time()\n",
        "\n",
        "avg_time_ms = (end - start) / 100 * 1000\n",
        "print(f\"⏱️ Avg inference time per image: {avg_time_ms:.2f} ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Itq475ny07By",
        "outputId": "2bbcf541-8b80-4b45-89a9-6c9b58918544"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏱️ Avg inference time per image: 0.53 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export CNN model"
      ],
      "metadata": {
        "id": "e9mkfuRN1vSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'model' is your trained model\n",
        "torch.save(model.state_dict(), \"custom_cnn_fire.pth\")"
      ],
      "metadata": {
        "id": "oh3vUye-17qq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkLgI3s-2Ga-",
        "outputId": "361f5d87-68e7-4c3f-8e24-266443e7cd65"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.4)\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Make sure model is on CPU for export or on the same device as dummy input\n",
        "model = CustomCNN()\n",
        "model.load_state_dict(torch.load(\"custom_cnn_fire.pth\"))\n",
        "model.eval()\n",
        "\n",
        "# Dummy input (batch size 1, 3 color channels, 224x224 image)\n",
        "dummy_input = torch.randn(1, 3, 224, 224)\n",
        "\n",
        "# Export to ONNX\n",
        "torch.onnx.export(\n",
        "    model,\n",
        "    dummy_input,\n",
        "    \"custom_cnn_fire.onnx\",\n",
        "    input_names=['input'],\n",
        "    output_names=['output'],\n",
        "    opset_version=11\n",
        ")\n",
        "\n",
        "print(\"✅ Exported as custom_cnn_fire.onnx — ready for Netron!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSQCBLqL1xNM",
        "outputId": "3d451c78-3615-4b30-8f9c-104d8339c588"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Exported as custom_cnn_fire.onnx — ready for Netron!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet-18 Model"
      ],
      "metadata": {
        "id": "yYDGLvR62-DI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colab crashed re adding dependencies"
      ],
      "metadata": {
        "id": "x9Br71m04CD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)  # Adjusting the final layer for 2 classes"
      ],
      "metadata": {
        "id": "0qAzOeov4Gdx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "V_GFDkQq4JT-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "XQ3tOolU49uD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, epochs=10, lr=0.001):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_acc = evaluate_model(model, val_loader)\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {running_loss/len(train_loader):.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "    return model\n",
        "\n",
        "def evaluate_model(model, val_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return 100 * correct / total\n"
      ],
      "metadata": {
        "id": "7Ox2QGAO5Awy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = train_model(model, fire_train_loader, fire_val_loader, epochs=10, lr=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXQCOrXz5EHi",
        "outputId": "6343e48a-f021-48a1-d123-a3f44901d9bc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Train Loss: 0.2406, Val Acc: 72.50%\n",
            "Epoch [2/10], Train Loss: 0.9308, Val Acc: 50.00%\n",
            "Epoch [3/10], Train Loss: 0.3574, Val Acc: 87.50%\n",
            "Epoch [4/10], Train Loss: 0.2588, Val Acc: 95.00%\n",
            "Epoch [5/10], Train Loss: 0.1480, Val Acc: 80.00%\n",
            "Epoch [6/10], Train Loss: 0.1324, Val Acc: 95.00%\n",
            "Epoch [7/10], Train Loss: 0.1193, Val Acc: 96.25%\n",
            "Epoch [8/10], Train Loss: 0.1167, Val Acc: 93.75%\n",
            "Epoch [9/10], Train Loss: 0.1394, Val Acc: 93.75%\n",
            "Epoch [10/10], Train Loss: 0.1179, Val Acc: 96.25%\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(trained_model.state_dict(), 'resnet18_fire_trained.pth')"
      ],
      "metadata": {
        "id": "ILvp25Wd6Ve5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPXBWAVc7Lzw",
        "outputId": "0832e818-fc31-4289-b1bd-4fd1b59642a5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.11/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "# Print model summary\n",
        "summary(model, (3, 224, 224))  # Assuming the input size is 224x224"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNYN7IDe7bl0",
        "outputId": "983b1352-a678-440f-ecec-ced734481656"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "             ReLU-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
            "             ReLU-17           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
            "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
            "             ReLU-21          [-1, 128, 28, 28]               0\n",
            "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
            "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
            "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
            "             ReLU-26          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
            "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
            "             ReLU-30          [-1, 128, 28, 28]               0\n",
            "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
            "             ReLU-33          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
            "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
            "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
            "             ReLU-37          [-1, 256, 14, 14]               0\n",
            "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
            "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
            "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
            "             ReLU-42          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
            "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
            "             ReLU-46          [-1, 256, 14, 14]               0\n",
            "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
            "             ReLU-49          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
            "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-53            [-1, 512, 7, 7]               0\n",
            "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
            "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-58            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
            "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-62            [-1, 512, 7, 7]               0\n",
            "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-65            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                    [-1, 2]           1,026\n",
            "================================================================\n",
            "Total params: 11,177,538\n",
            "Trainable params: 11,177,538\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 62.79\n",
            "Params size (MB): 42.64\n",
            "Estimated Total Size (MB): 106.00\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fvcore"
      ],
      "metadata": {
        "id": "zD9RvIEF8q70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "from fvcore.nn import FlopCountAnalysis\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Ensure the model is on the correct device\n",
        "model = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "model = model.to(device)\n",
        "\n",
        "# Initialize a dummy input to calculate FLOPs\n",
        "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
        "\n",
        "# Compute FLOPs using fvcore\n",
        "flops = FlopCountAnalysis(model, dummy_input)\n",
        "print(f\"FLOPs: {flops.total()}\")\n",
        "\n",
        "# Measure runtime on a batch of images\n",
        "def measure_inference_time(model, data_loader):\n",
        "    model.eval()\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            break  # Process just one batch\n",
        "    end_time = time.time()\n",
        "    avg_inference_time = (end_time - start_time) / len(data_loader.dataset)\n",
        "    return avg_inference_time\n",
        "\n",
        "# Assuming you have a DataLoader for your validation set\n",
        "batch_size = 32\n",
        "val_dataset = datasets.ImageFolder(root=wildfire_dataset_path, transform=transform)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Measure the inference time per image\n",
        "avg_inference_time = measure_inference_time(model, val_loader)\n",
        "print(f\"Average inference time per image: {avg_inference_time:.4f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pmF-Erg8l40",
        "outputId": "ffee37a9-016d-4e0f-ddb4-72f554e2723b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add_ encountered 28 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::max_pool2d encountered 1 time(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FLOPs: 1826006016\n",
            "Average inference time per image: 0.0014 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MobileNetV2 Model"
      ],
      "metadata": {
        "id": "wOIWjCEQ9dqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from torch.utils.data import DataLoader\n",
        "from torchsummary import summary\n",
        "\n",
        "# Load the pretrained MobileNetV2 model\n",
        "model = models.mobilenet_v2(pretrained=True)\n",
        "\n",
        "# Adjust the final fully connected layer for binary classification (2 classes)\n",
        "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)\n",
        "\n",
        "# Move model to the available device (GPU/CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLxUR7Lu9fnQ",
        "outputId": "99f37b84-edb1-48ed-cb01-49324a42d147"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 118MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, epochs=10, lr=0.001):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_acc = evaluate_model(model, val_loader)\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {running_loss/len(train_loader):.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "    return model\n",
        "\n",
        "def evaluate_model(model, val_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Train the model\n",
        "trained_model_mobilenet = train_model(model, fire_train_loader, fire_val_loader, epochs=10, lr=0.001)\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(trained_model_mobilenet.state_dict(), 'mobilenetv2_fire_trained.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9j5Wr4a9phe",
        "outputId": "14b0c582-ed3e-4de1-8db8-c23e96182129"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Train Loss: 0.1935, Val Acc: 100.00%\n",
            "Epoch [2/10], Train Loss: 0.6964, Val Acc: 50.00%\n",
            "Epoch [3/10], Train Loss: 0.5148, Val Acc: 50.00%\n",
            "Epoch [4/10], Train Loss: 0.5106, Val Acc: 50.00%\n",
            "Epoch [5/10], Train Loss: 0.5116, Val Acc: 50.00%\n",
            "Epoch [6/10], Train Loss: 0.5143, Val Acc: 50.00%\n",
            "Epoch [7/10], Train Loss: 0.5142, Val Acc: 50.00%\n",
            "Epoch [8/10], Train Loss: 0.5109, Val Acc: 50.00%\n",
            "Epoch [9/10], Train Loss: 0.5150, Val Acc: 50.00%\n",
            "Epoch [10/10], Train Loss: 0.5127, Val Acc: 50.00%\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Low accuracy due to imbalanced data. changing class weights and modifying code"
      ],
      "metadata": {
        "id": "A3xifyKV_Zff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "\n",
        "# Calculate class weights\n",
        "num_fire = 630\n",
        "num_non_fire = 164\n",
        "total_samples = num_fire + num_non_fire\n",
        "\n",
        "# Weight for each class (higher weight for the minority class \"non-fire\")\n",
        "fire_weight = total_samples / (2 * num_fire)  # For \"fire\" class\n",
        "non_fire_weight = total_samples / (2 * num_non_fire)  # For \"non-fire\" class\n",
        "\n",
        "# Assign weights to the classes\n",
        "class_weights = torch.tensor([fire_weight, non_fire_weight], device=device)\n",
        "\n",
        "# Define model, loss function with class weights, and optimizer\n",
        "model = models.mobilenet_v2(weights=\"IMAGENET1K_V1\")\n",
        "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)  # Adjust for 2 classes\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model as usual\n",
        "trained_model = train_model(model, fire_train_loader, fire_val_loader, epochs=10, lr=0.001)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wR1ll_m_jAo",
        "outputId": "f8096c7c-e627-4138-b12f-63da20249832"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Train Loss: 0.2566, Val Acc: 96.25%\n",
            "Epoch [2/10], Train Loss: 0.9531, Val Acc: 80.00%\n",
            "Epoch [3/10], Train Loss: 0.4370, Val Acc: 91.25%\n",
            "Epoch [4/10], Train Loss: 0.3778, Val Acc: 85.00%\n",
            "Epoch [5/10], Train Loss: 0.3499, Val Acc: 90.00%\n",
            "Epoch [6/10], Train Loss: 0.2698, Val Acc: 86.25%\n",
            "Epoch [7/10], Train Loss: 0.2858, Val Acc: 93.75%\n",
            "Epoch [8/10], Train Loss: 0.5097, Val Acc: 61.25%\n",
            "Epoch [9/10], Train Loss: 0.3635, Val Acc: 91.25%\n",
            "Epoch [10/10], Train Loss: 0.2296, Val Acc: 95.00%\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "# Get summary of the trained model (assuming input size is 224x224 for MobileNetV2)\n",
        "summary(trained_model, (3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4BFUV1DA9OT",
        "outputId": "cd3f9a55-30fd-4446-9c0a-e45f7f91488e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 112, 112]             864\n",
            "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
            "             ReLU6-3         [-1, 32, 112, 112]               0\n",
            "            Conv2d-4         [-1, 32, 112, 112]             288\n",
            "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
            "             ReLU6-6         [-1, 32, 112, 112]               0\n",
            "            Conv2d-7         [-1, 16, 112, 112]             512\n",
            "       BatchNorm2d-8         [-1, 16, 112, 112]              32\n",
            "  InvertedResidual-9         [-1, 16, 112, 112]               0\n",
            "           Conv2d-10         [-1, 96, 112, 112]           1,536\n",
            "      BatchNorm2d-11         [-1, 96, 112, 112]             192\n",
            "            ReLU6-12         [-1, 96, 112, 112]               0\n",
            "           Conv2d-13           [-1, 96, 56, 56]             864\n",
            "      BatchNorm2d-14           [-1, 96, 56, 56]             192\n",
            "            ReLU6-15           [-1, 96, 56, 56]               0\n",
            "           Conv2d-16           [-1, 24, 56, 56]           2,304\n",
            "      BatchNorm2d-17           [-1, 24, 56, 56]              48\n",
            " InvertedResidual-18           [-1, 24, 56, 56]               0\n",
            "           Conv2d-19          [-1, 144, 56, 56]           3,456\n",
            "      BatchNorm2d-20          [-1, 144, 56, 56]             288\n",
            "            ReLU6-21          [-1, 144, 56, 56]               0\n",
            "           Conv2d-22          [-1, 144, 56, 56]           1,296\n",
            "      BatchNorm2d-23          [-1, 144, 56, 56]             288\n",
            "            ReLU6-24          [-1, 144, 56, 56]               0\n",
            "           Conv2d-25           [-1, 24, 56, 56]           3,456\n",
            "      BatchNorm2d-26           [-1, 24, 56, 56]              48\n",
            " InvertedResidual-27           [-1, 24, 56, 56]               0\n",
            "           Conv2d-28          [-1, 144, 56, 56]           3,456\n",
            "      BatchNorm2d-29          [-1, 144, 56, 56]             288\n",
            "            ReLU6-30          [-1, 144, 56, 56]               0\n",
            "           Conv2d-31          [-1, 144, 28, 28]           1,296\n",
            "      BatchNorm2d-32          [-1, 144, 28, 28]             288\n",
            "            ReLU6-33          [-1, 144, 28, 28]               0\n",
            "           Conv2d-34           [-1, 32, 28, 28]           4,608\n",
            "      BatchNorm2d-35           [-1, 32, 28, 28]              64\n",
            " InvertedResidual-36           [-1, 32, 28, 28]               0\n",
            "           Conv2d-37          [-1, 192, 28, 28]           6,144\n",
            "      BatchNorm2d-38          [-1, 192, 28, 28]             384\n",
            "            ReLU6-39          [-1, 192, 28, 28]               0\n",
            "           Conv2d-40          [-1, 192, 28, 28]           1,728\n",
            "      BatchNorm2d-41          [-1, 192, 28, 28]             384\n",
            "            ReLU6-42          [-1, 192, 28, 28]               0\n",
            "           Conv2d-43           [-1, 32, 28, 28]           6,144\n",
            "      BatchNorm2d-44           [-1, 32, 28, 28]              64\n",
            " InvertedResidual-45           [-1, 32, 28, 28]               0\n",
            "           Conv2d-46          [-1, 192, 28, 28]           6,144\n",
            "      BatchNorm2d-47          [-1, 192, 28, 28]             384\n",
            "            ReLU6-48          [-1, 192, 28, 28]               0\n",
            "           Conv2d-49          [-1, 192, 28, 28]           1,728\n",
            "      BatchNorm2d-50          [-1, 192, 28, 28]             384\n",
            "            ReLU6-51          [-1, 192, 28, 28]               0\n",
            "           Conv2d-52           [-1, 32, 28, 28]           6,144\n",
            "      BatchNorm2d-53           [-1, 32, 28, 28]              64\n",
            " InvertedResidual-54           [-1, 32, 28, 28]               0\n",
            "           Conv2d-55          [-1, 192, 28, 28]           6,144\n",
            "      BatchNorm2d-56          [-1, 192, 28, 28]             384\n",
            "            ReLU6-57          [-1, 192, 28, 28]               0\n",
            "           Conv2d-58          [-1, 192, 14, 14]           1,728\n",
            "      BatchNorm2d-59          [-1, 192, 14, 14]             384\n",
            "            ReLU6-60          [-1, 192, 14, 14]               0\n",
            "           Conv2d-61           [-1, 64, 14, 14]          12,288\n",
            "      BatchNorm2d-62           [-1, 64, 14, 14]             128\n",
            " InvertedResidual-63           [-1, 64, 14, 14]               0\n",
            "           Conv2d-64          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-65          [-1, 384, 14, 14]             768\n",
            "            ReLU6-66          [-1, 384, 14, 14]               0\n",
            "           Conv2d-67          [-1, 384, 14, 14]           3,456\n",
            "      BatchNorm2d-68          [-1, 384, 14, 14]             768\n",
            "            ReLU6-69          [-1, 384, 14, 14]               0\n",
            "           Conv2d-70           [-1, 64, 14, 14]          24,576\n",
            "      BatchNorm2d-71           [-1, 64, 14, 14]             128\n",
            " InvertedResidual-72           [-1, 64, 14, 14]               0\n",
            "           Conv2d-73          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-74          [-1, 384, 14, 14]             768\n",
            "            ReLU6-75          [-1, 384, 14, 14]               0\n",
            "           Conv2d-76          [-1, 384, 14, 14]           3,456\n",
            "      BatchNorm2d-77          [-1, 384, 14, 14]             768\n",
            "            ReLU6-78          [-1, 384, 14, 14]               0\n",
            "           Conv2d-79           [-1, 64, 14, 14]          24,576\n",
            "      BatchNorm2d-80           [-1, 64, 14, 14]             128\n",
            " InvertedResidual-81           [-1, 64, 14, 14]               0\n",
            "           Conv2d-82          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-83          [-1, 384, 14, 14]             768\n",
            "            ReLU6-84          [-1, 384, 14, 14]               0\n",
            "           Conv2d-85          [-1, 384, 14, 14]           3,456\n",
            "      BatchNorm2d-86          [-1, 384, 14, 14]             768\n",
            "            ReLU6-87          [-1, 384, 14, 14]               0\n",
            "           Conv2d-88           [-1, 64, 14, 14]          24,576\n",
            "      BatchNorm2d-89           [-1, 64, 14, 14]             128\n",
            " InvertedResidual-90           [-1, 64, 14, 14]               0\n",
            "           Conv2d-91          [-1, 384, 14, 14]          24,576\n",
            "      BatchNorm2d-92          [-1, 384, 14, 14]             768\n",
            "            ReLU6-93          [-1, 384, 14, 14]               0\n",
            "           Conv2d-94          [-1, 384, 14, 14]           3,456\n",
            "      BatchNorm2d-95          [-1, 384, 14, 14]             768\n",
            "            ReLU6-96          [-1, 384, 14, 14]               0\n",
            "           Conv2d-97           [-1, 96, 14, 14]          36,864\n",
            "      BatchNorm2d-98           [-1, 96, 14, 14]             192\n",
            " InvertedResidual-99           [-1, 96, 14, 14]               0\n",
            "          Conv2d-100          [-1, 576, 14, 14]          55,296\n",
            "     BatchNorm2d-101          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-102          [-1, 576, 14, 14]               0\n",
            "          Conv2d-103          [-1, 576, 14, 14]           5,184\n",
            "     BatchNorm2d-104          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-105          [-1, 576, 14, 14]               0\n",
            "          Conv2d-106           [-1, 96, 14, 14]          55,296\n",
            "     BatchNorm2d-107           [-1, 96, 14, 14]             192\n",
            "InvertedResidual-108           [-1, 96, 14, 14]               0\n",
            "          Conv2d-109          [-1, 576, 14, 14]          55,296\n",
            "     BatchNorm2d-110          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-111          [-1, 576, 14, 14]               0\n",
            "          Conv2d-112          [-1, 576, 14, 14]           5,184\n",
            "     BatchNorm2d-113          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-114          [-1, 576, 14, 14]               0\n",
            "          Conv2d-115           [-1, 96, 14, 14]          55,296\n",
            "     BatchNorm2d-116           [-1, 96, 14, 14]             192\n",
            "InvertedResidual-117           [-1, 96, 14, 14]               0\n",
            "          Conv2d-118          [-1, 576, 14, 14]          55,296\n",
            "     BatchNorm2d-119          [-1, 576, 14, 14]           1,152\n",
            "           ReLU6-120          [-1, 576, 14, 14]               0\n",
            "          Conv2d-121            [-1, 576, 7, 7]           5,184\n",
            "     BatchNorm2d-122            [-1, 576, 7, 7]           1,152\n",
            "           ReLU6-123            [-1, 576, 7, 7]               0\n",
            "          Conv2d-124            [-1, 160, 7, 7]          92,160\n",
            "     BatchNorm2d-125            [-1, 160, 7, 7]             320\n",
            "InvertedResidual-126            [-1, 160, 7, 7]               0\n",
            "          Conv2d-127            [-1, 960, 7, 7]         153,600\n",
            "     BatchNorm2d-128            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-129            [-1, 960, 7, 7]               0\n",
            "          Conv2d-130            [-1, 960, 7, 7]           8,640\n",
            "     BatchNorm2d-131            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-132            [-1, 960, 7, 7]               0\n",
            "          Conv2d-133            [-1, 160, 7, 7]         153,600\n",
            "     BatchNorm2d-134            [-1, 160, 7, 7]             320\n",
            "InvertedResidual-135            [-1, 160, 7, 7]               0\n",
            "          Conv2d-136            [-1, 960, 7, 7]         153,600\n",
            "     BatchNorm2d-137            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-138            [-1, 960, 7, 7]               0\n",
            "          Conv2d-139            [-1, 960, 7, 7]           8,640\n",
            "     BatchNorm2d-140            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-141            [-1, 960, 7, 7]               0\n",
            "          Conv2d-142            [-1, 160, 7, 7]         153,600\n",
            "     BatchNorm2d-143            [-1, 160, 7, 7]             320\n",
            "InvertedResidual-144            [-1, 160, 7, 7]               0\n",
            "          Conv2d-145            [-1, 960, 7, 7]         153,600\n",
            "     BatchNorm2d-146            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-147            [-1, 960, 7, 7]               0\n",
            "          Conv2d-148            [-1, 960, 7, 7]           8,640\n",
            "     BatchNorm2d-149            [-1, 960, 7, 7]           1,920\n",
            "           ReLU6-150            [-1, 960, 7, 7]               0\n",
            "          Conv2d-151            [-1, 320, 7, 7]         307,200\n",
            "     BatchNorm2d-152            [-1, 320, 7, 7]             640\n",
            "InvertedResidual-153            [-1, 320, 7, 7]               0\n",
            "          Conv2d-154           [-1, 1280, 7, 7]         409,600\n",
            "     BatchNorm2d-155           [-1, 1280, 7, 7]           2,560\n",
            "           ReLU6-156           [-1, 1280, 7, 7]               0\n",
            "         Dropout-157                 [-1, 1280]               0\n",
            "          Linear-158                    [-1, 2]           2,562\n",
            "================================================================\n",
            "Total params: 2,226,434\n",
            "Trainable params: 2,226,434\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 152.86\n",
            "Params size (MB): 8.49\n",
            "Estimated Total Size (MB): 161.93\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fvcore.nn import FlopCountAnalysis\n",
        "import time\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "# Move model to eval mode and CPU for FLOPs calculation\n",
        "trained_model.eval()\n",
        "trained_model.cpu()\n",
        "\n",
        "# Dummy input\n",
        "dummy_input = torch.randn(1, 3, 224, 224)\n",
        "\n",
        "# FLOPs calculation\n",
        "flops = FlopCountAnalysis(trained_model, dummy_input)\n",
        "print(f\"FLOPs: {flops.total()}\")\n",
        "\n",
        "# Inference time calculation\n",
        "trained_model.eval()\n",
        "trained_model.to(device)\n",
        "dummy_input = dummy_input.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    start_time = time.time()\n",
        "    for _ in range(100):\n",
        "        _ = trained_model(dummy_input)\n",
        "    end_time = time.time()\n",
        "\n",
        "avg_inference_time = (end_time - start_time) / 100\n",
        "print(f\"Average inference time per image: {avg_inference_time:.4f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eh335HCeB7j6",
        "outputId": "0a16a554-d8a5-4333-9329-4593a9c5d972"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::hardtanh_ encountered 35 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add encountered 10 time(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FLOPs: 312915776\n",
            "Average inference time per image: 0.0058 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EfficientNetB0"
      ],
      "metadata": {
        "id": "Af-4x4hHChUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import efficientnet_b0\n",
        "\n",
        "# Load pretrained EfficientNetB0\n",
        "model = efficientnet_b0(weights=\"IMAGENET1K_V1\")\n",
        "\n",
        "# Modify final classifier layer for 2 classes\n",
        "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)\n",
        "\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEnVUgj-Cg2n",
        "outputId": "87b68751-cfbc-41d9-b79d-f0b6e53c658b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 140MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reuse class weights from earlier\n",
        "weights = torch.tensor([1.0, 630/164], dtype=torch.float).to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=weights)"
      ],
      "metadata": {
        "id": "-LCLx3jSCozz"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "trained_model = train_model(model, fire_train_loader, fire_val_loader, epochs=10, lr=0.001)\n",
        "torch.save(trained_model.state_dict(), 'efficientnetb0_fire_trained.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IySfYQOeCts8",
        "outputId": "a03d749b-80d6-4b20-9ac5-c51107428872"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Train Loss: 0.1938, Val Acc: 98.75%\n",
            "Epoch [2/10], Train Loss: 155.6686, Val Acc: 52.50%\n",
            "Epoch [3/10], Train Loss: 59.1824, Val Acc: 41.25%\n",
            "Epoch [4/10], Train Loss: 48.3075, Val Acc: 50.00%\n",
            "Epoch [5/10], Train Loss: 4.0257, Val Acc: 32.50%\n",
            "Epoch [6/10], Train Loss: 0.8582, Val Acc: 50.00%\n",
            "Epoch [7/10], Train Loss: 0.7048, Val Acc: 50.00%\n",
            "Epoch [8/10], Train Loss: 0.6945, Val Acc: 50.00%\n",
            "Epoch [9/10], Train Loss: 0.6938, Val Acc: 50.00%\n",
            "Epoch [10/10], Train Loss: 0.6934, Val Acc: 50.00%\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(trained_model, (3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnTIYjFvEKoX",
        "outputId": "fa8f98df-3f98-4cc8-a839-7847d9f491ce"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 112, 112]             864\n",
            "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
            "              SiLU-3         [-1, 32, 112, 112]               0\n",
            "            Conv2d-4         [-1, 32, 112, 112]             288\n",
            "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
            "              SiLU-6         [-1, 32, 112, 112]               0\n",
            " AdaptiveAvgPool2d-7             [-1, 32, 1, 1]               0\n",
            "            Conv2d-8              [-1, 8, 1, 1]             264\n",
            "              SiLU-9              [-1, 8, 1, 1]               0\n",
            "           Conv2d-10             [-1, 32, 1, 1]             288\n",
            "          Sigmoid-11             [-1, 32, 1, 1]               0\n",
            "SqueezeExcitation-12         [-1, 32, 112, 112]               0\n",
            "           Conv2d-13         [-1, 16, 112, 112]             512\n",
            "      BatchNorm2d-14         [-1, 16, 112, 112]              32\n",
            "           MBConv-15         [-1, 16, 112, 112]               0\n",
            "           Conv2d-16         [-1, 96, 112, 112]           1,536\n",
            "      BatchNorm2d-17         [-1, 96, 112, 112]             192\n",
            "             SiLU-18         [-1, 96, 112, 112]               0\n",
            "           Conv2d-19           [-1, 96, 56, 56]             864\n",
            "      BatchNorm2d-20           [-1, 96, 56, 56]             192\n",
            "             SiLU-21           [-1, 96, 56, 56]               0\n",
            "AdaptiveAvgPool2d-22             [-1, 96, 1, 1]               0\n",
            "           Conv2d-23              [-1, 4, 1, 1]             388\n",
            "             SiLU-24              [-1, 4, 1, 1]               0\n",
            "           Conv2d-25             [-1, 96, 1, 1]             480\n",
            "          Sigmoid-26             [-1, 96, 1, 1]               0\n",
            "SqueezeExcitation-27           [-1, 96, 56, 56]               0\n",
            "           Conv2d-28           [-1, 24, 56, 56]           2,304\n",
            "      BatchNorm2d-29           [-1, 24, 56, 56]              48\n",
            "           MBConv-30           [-1, 24, 56, 56]               0\n",
            "           Conv2d-31          [-1, 144, 56, 56]           3,456\n",
            "      BatchNorm2d-32          [-1, 144, 56, 56]             288\n",
            "             SiLU-33          [-1, 144, 56, 56]               0\n",
            "           Conv2d-34          [-1, 144, 56, 56]           1,296\n",
            "      BatchNorm2d-35          [-1, 144, 56, 56]             288\n",
            "             SiLU-36          [-1, 144, 56, 56]               0\n",
            "AdaptiveAvgPool2d-37            [-1, 144, 1, 1]               0\n",
            "           Conv2d-38              [-1, 6, 1, 1]             870\n",
            "             SiLU-39              [-1, 6, 1, 1]               0\n",
            "           Conv2d-40            [-1, 144, 1, 1]           1,008\n",
            "          Sigmoid-41            [-1, 144, 1, 1]               0\n",
            "SqueezeExcitation-42          [-1, 144, 56, 56]               0\n",
            "           Conv2d-43           [-1, 24, 56, 56]           3,456\n",
            "      BatchNorm2d-44           [-1, 24, 56, 56]              48\n",
            "  StochasticDepth-45           [-1, 24, 56, 56]               0\n",
            "           MBConv-46           [-1, 24, 56, 56]               0\n",
            "           Conv2d-47          [-1, 144, 56, 56]           3,456\n",
            "      BatchNorm2d-48          [-1, 144, 56, 56]             288\n",
            "             SiLU-49          [-1, 144, 56, 56]               0\n",
            "           Conv2d-50          [-1, 144, 28, 28]           3,600\n",
            "      BatchNorm2d-51          [-1, 144, 28, 28]             288\n",
            "             SiLU-52          [-1, 144, 28, 28]               0\n",
            "AdaptiveAvgPool2d-53            [-1, 144, 1, 1]               0\n",
            "           Conv2d-54              [-1, 6, 1, 1]             870\n",
            "             SiLU-55              [-1, 6, 1, 1]               0\n",
            "           Conv2d-56            [-1, 144, 1, 1]           1,008\n",
            "          Sigmoid-57            [-1, 144, 1, 1]               0\n",
            "SqueezeExcitation-58          [-1, 144, 28, 28]               0\n",
            "           Conv2d-59           [-1, 40, 28, 28]           5,760\n",
            "      BatchNorm2d-60           [-1, 40, 28, 28]              80\n",
            "           MBConv-61           [-1, 40, 28, 28]               0\n",
            "           Conv2d-62          [-1, 240, 28, 28]           9,600\n",
            "      BatchNorm2d-63          [-1, 240, 28, 28]             480\n",
            "             SiLU-64          [-1, 240, 28, 28]               0\n",
            "           Conv2d-65          [-1, 240, 28, 28]           6,000\n",
            "      BatchNorm2d-66          [-1, 240, 28, 28]             480\n",
            "             SiLU-67          [-1, 240, 28, 28]               0\n",
            "AdaptiveAvgPool2d-68            [-1, 240, 1, 1]               0\n",
            "           Conv2d-69             [-1, 10, 1, 1]           2,410\n",
            "             SiLU-70             [-1, 10, 1, 1]               0\n",
            "           Conv2d-71            [-1, 240, 1, 1]           2,640\n",
            "          Sigmoid-72            [-1, 240, 1, 1]               0\n",
            "SqueezeExcitation-73          [-1, 240, 28, 28]               0\n",
            "           Conv2d-74           [-1, 40, 28, 28]           9,600\n",
            "      BatchNorm2d-75           [-1, 40, 28, 28]              80\n",
            "  StochasticDepth-76           [-1, 40, 28, 28]               0\n",
            "           MBConv-77           [-1, 40, 28, 28]               0\n",
            "           Conv2d-78          [-1, 240, 28, 28]           9,600\n",
            "      BatchNorm2d-79          [-1, 240, 28, 28]             480\n",
            "             SiLU-80          [-1, 240, 28, 28]               0\n",
            "           Conv2d-81          [-1, 240, 14, 14]           2,160\n",
            "      BatchNorm2d-82          [-1, 240, 14, 14]             480\n",
            "             SiLU-83          [-1, 240, 14, 14]               0\n",
            "AdaptiveAvgPool2d-84            [-1, 240, 1, 1]               0\n",
            "           Conv2d-85             [-1, 10, 1, 1]           2,410\n",
            "             SiLU-86             [-1, 10, 1, 1]               0\n",
            "           Conv2d-87            [-1, 240, 1, 1]           2,640\n",
            "          Sigmoid-88            [-1, 240, 1, 1]               0\n",
            "SqueezeExcitation-89          [-1, 240, 14, 14]               0\n",
            "           Conv2d-90           [-1, 80, 14, 14]          19,200\n",
            "      BatchNorm2d-91           [-1, 80, 14, 14]             160\n",
            "           MBConv-92           [-1, 80, 14, 14]               0\n",
            "           Conv2d-93          [-1, 480, 14, 14]          38,400\n",
            "      BatchNorm2d-94          [-1, 480, 14, 14]             960\n",
            "             SiLU-95          [-1, 480, 14, 14]               0\n",
            "           Conv2d-96          [-1, 480, 14, 14]           4,320\n",
            "      BatchNorm2d-97          [-1, 480, 14, 14]             960\n",
            "             SiLU-98          [-1, 480, 14, 14]               0\n",
            "AdaptiveAvgPool2d-99            [-1, 480, 1, 1]               0\n",
            "          Conv2d-100             [-1, 20, 1, 1]           9,620\n",
            "            SiLU-101             [-1, 20, 1, 1]               0\n",
            "          Conv2d-102            [-1, 480, 1, 1]          10,080\n",
            "         Sigmoid-103            [-1, 480, 1, 1]               0\n",
            "SqueezeExcitation-104          [-1, 480, 14, 14]               0\n",
            "          Conv2d-105           [-1, 80, 14, 14]          38,400\n",
            "     BatchNorm2d-106           [-1, 80, 14, 14]             160\n",
            " StochasticDepth-107           [-1, 80, 14, 14]               0\n",
            "          MBConv-108           [-1, 80, 14, 14]               0\n",
            "          Conv2d-109          [-1, 480, 14, 14]          38,400\n",
            "     BatchNorm2d-110          [-1, 480, 14, 14]             960\n",
            "            SiLU-111          [-1, 480, 14, 14]               0\n",
            "          Conv2d-112          [-1, 480, 14, 14]           4,320\n",
            "     BatchNorm2d-113          [-1, 480, 14, 14]             960\n",
            "            SiLU-114          [-1, 480, 14, 14]               0\n",
            "AdaptiveAvgPool2d-115            [-1, 480, 1, 1]               0\n",
            "          Conv2d-116             [-1, 20, 1, 1]           9,620\n",
            "            SiLU-117             [-1, 20, 1, 1]               0\n",
            "          Conv2d-118            [-1, 480, 1, 1]          10,080\n",
            "         Sigmoid-119            [-1, 480, 1, 1]               0\n",
            "SqueezeExcitation-120          [-1, 480, 14, 14]               0\n",
            "          Conv2d-121           [-1, 80, 14, 14]          38,400\n",
            "     BatchNorm2d-122           [-1, 80, 14, 14]             160\n",
            " StochasticDepth-123           [-1, 80, 14, 14]               0\n",
            "          MBConv-124           [-1, 80, 14, 14]               0\n",
            "          Conv2d-125          [-1, 480, 14, 14]          38,400\n",
            "     BatchNorm2d-126          [-1, 480, 14, 14]             960\n",
            "            SiLU-127          [-1, 480, 14, 14]               0\n",
            "          Conv2d-128          [-1, 480, 14, 14]          12,000\n",
            "     BatchNorm2d-129          [-1, 480, 14, 14]             960\n",
            "            SiLU-130          [-1, 480, 14, 14]               0\n",
            "AdaptiveAvgPool2d-131            [-1, 480, 1, 1]               0\n",
            "          Conv2d-132             [-1, 20, 1, 1]           9,620\n",
            "            SiLU-133             [-1, 20, 1, 1]               0\n",
            "          Conv2d-134            [-1, 480, 1, 1]          10,080\n",
            "         Sigmoid-135            [-1, 480, 1, 1]               0\n",
            "SqueezeExcitation-136          [-1, 480, 14, 14]               0\n",
            "          Conv2d-137          [-1, 112, 14, 14]          53,760\n",
            "     BatchNorm2d-138          [-1, 112, 14, 14]             224\n",
            "          MBConv-139          [-1, 112, 14, 14]               0\n",
            "          Conv2d-140          [-1, 672, 14, 14]          75,264\n",
            "     BatchNorm2d-141          [-1, 672, 14, 14]           1,344\n",
            "            SiLU-142          [-1, 672, 14, 14]               0\n",
            "          Conv2d-143          [-1, 672, 14, 14]          16,800\n",
            "     BatchNorm2d-144          [-1, 672, 14, 14]           1,344\n",
            "            SiLU-145          [-1, 672, 14, 14]               0\n",
            "AdaptiveAvgPool2d-146            [-1, 672, 1, 1]               0\n",
            "          Conv2d-147             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-148             [-1, 28, 1, 1]               0\n",
            "          Conv2d-149            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-150            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-151          [-1, 672, 14, 14]               0\n",
            "          Conv2d-152          [-1, 112, 14, 14]          75,264\n",
            "     BatchNorm2d-153          [-1, 112, 14, 14]             224\n",
            " StochasticDepth-154          [-1, 112, 14, 14]               0\n",
            "          MBConv-155          [-1, 112, 14, 14]               0\n",
            "          Conv2d-156          [-1, 672, 14, 14]          75,264\n",
            "     BatchNorm2d-157          [-1, 672, 14, 14]           1,344\n",
            "            SiLU-158          [-1, 672, 14, 14]               0\n",
            "          Conv2d-159          [-1, 672, 14, 14]          16,800\n",
            "     BatchNorm2d-160          [-1, 672, 14, 14]           1,344\n",
            "            SiLU-161          [-1, 672, 14, 14]               0\n",
            "AdaptiveAvgPool2d-162            [-1, 672, 1, 1]               0\n",
            "          Conv2d-163             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-164             [-1, 28, 1, 1]               0\n",
            "          Conv2d-165            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-166            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-167          [-1, 672, 14, 14]               0\n",
            "          Conv2d-168          [-1, 112, 14, 14]          75,264\n",
            "     BatchNorm2d-169          [-1, 112, 14, 14]             224\n",
            " StochasticDepth-170          [-1, 112, 14, 14]               0\n",
            "          MBConv-171          [-1, 112, 14, 14]               0\n",
            "          Conv2d-172          [-1, 672, 14, 14]          75,264\n",
            "     BatchNorm2d-173          [-1, 672, 14, 14]           1,344\n",
            "            SiLU-174          [-1, 672, 14, 14]               0\n",
            "          Conv2d-175            [-1, 672, 7, 7]          16,800\n",
            "     BatchNorm2d-176            [-1, 672, 7, 7]           1,344\n",
            "            SiLU-177            [-1, 672, 7, 7]               0\n",
            "AdaptiveAvgPool2d-178            [-1, 672, 1, 1]               0\n",
            "          Conv2d-179             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-180             [-1, 28, 1, 1]               0\n",
            "          Conv2d-181            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-182            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-183            [-1, 672, 7, 7]               0\n",
            "          Conv2d-184            [-1, 192, 7, 7]         129,024\n",
            "     BatchNorm2d-185            [-1, 192, 7, 7]             384\n",
            "          MBConv-186            [-1, 192, 7, 7]               0\n",
            "          Conv2d-187           [-1, 1152, 7, 7]         221,184\n",
            "     BatchNorm2d-188           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-189           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-190           [-1, 1152, 7, 7]          28,800\n",
            "     BatchNorm2d-191           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-192           [-1, 1152, 7, 7]               0\n",
            "AdaptiveAvgPool2d-193           [-1, 1152, 1, 1]               0\n",
            "          Conv2d-194             [-1, 48, 1, 1]          55,344\n",
            "            SiLU-195             [-1, 48, 1, 1]               0\n",
            "          Conv2d-196           [-1, 1152, 1, 1]          56,448\n",
            "         Sigmoid-197           [-1, 1152, 1, 1]               0\n",
            "SqueezeExcitation-198           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-199            [-1, 192, 7, 7]         221,184\n",
            "     BatchNorm2d-200            [-1, 192, 7, 7]             384\n",
            " StochasticDepth-201            [-1, 192, 7, 7]               0\n",
            "          MBConv-202            [-1, 192, 7, 7]               0\n",
            "          Conv2d-203           [-1, 1152, 7, 7]         221,184\n",
            "     BatchNorm2d-204           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-205           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-206           [-1, 1152, 7, 7]          28,800\n",
            "     BatchNorm2d-207           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-208           [-1, 1152, 7, 7]               0\n",
            "AdaptiveAvgPool2d-209           [-1, 1152, 1, 1]               0\n",
            "          Conv2d-210             [-1, 48, 1, 1]          55,344\n",
            "            SiLU-211             [-1, 48, 1, 1]               0\n",
            "          Conv2d-212           [-1, 1152, 1, 1]          56,448\n",
            "         Sigmoid-213           [-1, 1152, 1, 1]               0\n",
            "SqueezeExcitation-214           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-215            [-1, 192, 7, 7]         221,184\n",
            "     BatchNorm2d-216            [-1, 192, 7, 7]             384\n",
            " StochasticDepth-217            [-1, 192, 7, 7]               0\n",
            "          MBConv-218            [-1, 192, 7, 7]               0\n",
            "          Conv2d-219           [-1, 1152, 7, 7]         221,184\n",
            "     BatchNorm2d-220           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-221           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-222           [-1, 1152, 7, 7]          28,800\n",
            "     BatchNorm2d-223           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-224           [-1, 1152, 7, 7]               0\n",
            "AdaptiveAvgPool2d-225           [-1, 1152, 1, 1]               0\n",
            "          Conv2d-226             [-1, 48, 1, 1]          55,344\n",
            "            SiLU-227             [-1, 48, 1, 1]               0\n",
            "          Conv2d-228           [-1, 1152, 1, 1]          56,448\n",
            "         Sigmoid-229           [-1, 1152, 1, 1]               0\n",
            "SqueezeExcitation-230           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-231            [-1, 192, 7, 7]         221,184\n",
            "     BatchNorm2d-232            [-1, 192, 7, 7]             384\n",
            " StochasticDepth-233            [-1, 192, 7, 7]               0\n",
            "          MBConv-234            [-1, 192, 7, 7]               0\n",
            "          Conv2d-235           [-1, 1152, 7, 7]         221,184\n",
            "     BatchNorm2d-236           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-237           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-238           [-1, 1152, 7, 7]          10,368\n",
            "     BatchNorm2d-239           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-240           [-1, 1152, 7, 7]               0\n",
            "AdaptiveAvgPool2d-241           [-1, 1152, 1, 1]               0\n",
            "          Conv2d-242             [-1, 48, 1, 1]          55,344\n",
            "            SiLU-243             [-1, 48, 1, 1]               0\n",
            "          Conv2d-244           [-1, 1152, 1, 1]          56,448\n",
            "         Sigmoid-245           [-1, 1152, 1, 1]               0\n",
            "SqueezeExcitation-246           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-247            [-1, 320, 7, 7]         368,640\n",
            "     BatchNorm2d-248            [-1, 320, 7, 7]             640\n",
            "          MBConv-249            [-1, 320, 7, 7]               0\n",
            "          Conv2d-250           [-1, 1280, 7, 7]         409,600\n",
            "     BatchNorm2d-251           [-1, 1280, 7, 7]           2,560\n",
            "            SiLU-252           [-1, 1280, 7, 7]               0\n",
            "AdaptiveAvgPool2d-253           [-1, 1280, 1, 1]               0\n",
            "         Dropout-254                 [-1, 1280]               0\n",
            "          Linear-255                    [-1, 2]           2,562\n",
            "================================================================\n",
            "Total params: 4,010,110\n",
            "Trainable params: 4,010,110\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 173.64\n",
            "Params size (MB): 15.30\n",
            "Estimated Total Size (MB): 189.52\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fvcore.nn import FlopCountAnalysis\n",
        "import time\n",
        "\n",
        "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
        "\n",
        "# FLOPs\n",
        "flops = FlopCountAnalysis(model, dummy_input)\n",
        "print(f\"FLOPs: {flops.total()}\")\n",
        "\n",
        "# Inference time\n",
        "start_time = time.time()\n",
        "with torch.no_grad():\n",
        "    for _ in range(100):\n",
        "        _ = model(dummy_input)\n",
        "end_time = time.time()\n",
        "print(f\"Average inference time per image: {(end_time - start_time)/100:.4f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqSFNWNcEW3e",
        "outputId": "f56ad3c2-1dfc-403e-dcb9-611ba6a401ba"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::silu_ encountered 49 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::sigmoid encountered 16 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::mul encountered 16 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add_ encountered 9 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::dropout_ encountered 1 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
            "features.1.0.stochastic_depth, features.2.0.stochastic_depth, features.2.1.stochastic_depth, features.3.0.stochastic_depth, features.3.1.stochastic_depth, features.4.0.stochastic_depth, features.4.1.stochastic_depth, features.4.2.stochastic_depth, features.5.0.stochastic_depth, features.5.1.stochastic_depth, features.5.2.stochastic_depth, features.6.0.stochastic_depth, features.6.1.stochastic_depth, features.6.2.stochastic_depth, features.6.3.stochastic_depth, features.7.0.stochastic_depth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FLOPs: 400381952\n",
            "Average inference time per image: 0.0105 seconds\n"
          ]
        }
      ]
    }
  ]
}